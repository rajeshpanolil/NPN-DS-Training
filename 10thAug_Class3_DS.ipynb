{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Main Heading\n",
    "## Sub Heading\n",
    "### One more level down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10th August - Class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>San</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ram</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Name  Salary\n",
       "0   1  San   30000\n",
       "1   2  Ram   40000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining a dataframe. This is rarely used as all dataframes are imported from another format. This is how we import DataFrame\n",
    "# as a list not as a dictionary\n",
    "pd.DataFrame([[1,\"San\",30000,],[2,\"Ram\",40000]],index = [0,1],columns = [\"ID\",\"Name\",\"Salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Name\n",
       "0   1    A\n",
       "1   2    B\n",
       "2   3    C\n",
       "3   4    D"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"id\":[1,2,3,4],\"Name\":[\"A\",\"B\",\"C\",\"D\"]})\n",
    "#this is more a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id Name\n",
       "10   1    A\n",
       "20   2    B\n",
       "30   3    C\n",
       "40   4    D"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"id\":[1,2,3,4],\"Name\":[\"A\",\"B\",\"C\",\"D\"]},index = [10,20,30,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'A'],\n",
       "       [2, 'B'],\n",
       "       [3, 'C'],\n",
       "       [4, 'D']], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"id\":[1,2,3,4],\"Name\":[\"A\",\"B\",\"C\",\"D\"]},index = [10,20,30,40]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a series\n",
    "pd.Series([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    1\n",
       "20    2\n",
       "30    3\n",
       "40    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a series\n",
    "pd.Series([1,2,3,4],index = [10,20,30,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to read a csv files using pandas. How easy it is!\n",
    "new_excel = pd.read_excel(\"C:/Users/tin2419/Desktop/Time Report.xlsx\")\n",
    "#,skiprows=4,nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_excel in module pandas.io.excel:\n",
      "\n",
      "read_excel(io, sheet_name=0, header=0, names=None, index_col=None, parse_cols=None, usecols=None, squeeze=False, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, verbose=False, parse_dates=False, date_parser=None, thousands=None, comment=None, skip_footer=0, skipfooter=0, convert_float=True, mangle_dupe_cols=True, **kwds)\n",
      "    Read an Excel file into a pandas DataFrame.\n",
      "    \n",
      "    Support both `xls` and `xlsx` file extensions from a local filesystem or URL.\n",
      "    Support an option to read a single sheet or a list of sheets.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    io : str, file descriptor, pathlib.Path, ExcelFile or xlrd.Book\n",
      "        The string could be a URL. Valid URL schemes include http, ftp, s3,\n",
      "        gcs, and file. For file URLs, a host is expected. For instance, a local\n",
      "        file could be /path/to/workbook.xlsx.\n",
      "    sheet_name : str, int, list, or None, default 0\n",
      "        Strings are used for sheet names. Integers are used in zero-indexed\n",
      "        sheet positions. Lists of strings/integers are used to request\n",
      "        multiple sheets. Specify None to get all sheets.\n",
      "    \n",
      "        Available cases:\n",
      "    \n",
      "        * Defaults to ``0``: 1st sheet as a `DataFrame`\n",
      "        * ``1``: 2nd sheet as a `DataFrame`\n",
      "        * ``\"Sheet1\"``: Load sheet with name \"Sheet1\"\n",
      "        * ``[0, 1, \"Sheet5\"]``: Load first, second and sheet named \"Sheet5\"\n",
      "          as a dict of `DataFrame`\n",
      "        * None: All sheets.\n",
      "    \n",
      "    header : int, list of int, default 0\n",
      "        Row (0-indexed) to use for the column labels of the parsed\n",
      "        DataFrame. If a list of integers is passed those row positions will\n",
      "        be combined into a ``MultiIndex``. Use None if there is no header.\n",
      "    names : array-like, default None\n",
      "        List of column names to use. If file contains no header row,\n",
      "        then you should explicitly pass header=None.\n",
      "    index_col : int, list of int, default None\n",
      "        Column (0-indexed) to use as the row labels of the DataFrame.\n",
      "        Pass None if there is no such column.  If a list is passed,\n",
      "        those columns will be combined into a ``MultiIndex``.  If a\n",
      "        subset of data is selected with ``usecols``, index_col\n",
      "        is based on the subset.\n",
      "    parse_cols : int or list, default None\n",
      "        Alias of `usecols`.\n",
      "    \n",
      "        .. deprecated:: 0.21.0\n",
      "           Use `usecols` instead.\n",
      "    \n",
      "    usecols : int, str, list-like, or callable default None\n",
      "        Return a subset of the columns.\n",
      "        * If None, then parse all columns.\n",
      "        * If int, then indicates last column to be parsed.\n",
      "    \n",
      "        .. deprecated:: 0.24.0\n",
      "           Pass in a list of int instead from 0 to `usecols` inclusive.\n",
      "    \n",
      "        * If str, then indicates comma separated list of Excel column letters\n",
      "          and column ranges (e.g. \"A:E\" or \"A,C,E:F\"). Ranges are inclusive of\n",
      "          both sides.\n",
      "        * If list of int, then indicates list of column numbers to be parsed.\n",
      "        * If list of string, then indicates list of column names to be parsed.\n",
      "    \n",
      "        .. versionadded:: 0.24.0\n",
      "    \n",
      "        * If callable, then evaluate each column name against it and parse the\n",
      "          column if the callable returns ``True``.\n",
      "    \n",
      "        .. versionadded:: 0.24.0\n",
      "    \n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    dtype : Type name or dict of column -> type, default None\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "        Use `object` to preserve data as stored in Excel and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    \n",
      "        .. versionadded:: 0.20.0\n",
      "    \n",
      "    engine : str, default None\n",
      "        If io is not a buffer or path, this must be set to identify io.\n",
      "        Acceptable values are None or xlrd.\n",
      "    converters : dict, default None\n",
      "        Dict of functions for converting values in certain columns. Keys can\n",
      "        either be integers or column labels, values are functions that take one\n",
      "        input argument, the Excel cell content, and return the transformed\n",
      "        content.\n",
      "    true_values : list, default None\n",
      "        Values to consider as True.\n",
      "    \n",
      "        .. versionadded:: 0.19.0\n",
      "    \n",
      "    false_values : list, default None\n",
      "        Values to consider as False.\n",
      "    \n",
      "        .. versionadded:: 0.19.0\n",
      "    \n",
      "    skiprows : list-like\n",
      "        Rows to skip at the beginning (0-indexed).\n",
      "    nrows : int, default None\n",
      "        Number of rows to parse.\n",
      "    \n",
      "        .. versionadded:: 0.23.0\n",
      "    \n",
      "    na_values : scalar, str, list-like, or dict, default None\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values. By default the following values are interpreted\n",
      "        as NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan',\n",
      "        'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        If na_values are specified and keep_default_na is False the default NaN\n",
      "        values are overridden, otherwise they're appended to.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    parse_dates : bool, list-like, or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * bool. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {{'foo' : [1, 3]}} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index contains an unparseable date, the entire column or\n",
      "        index will be returned unaltered as an object data type. For non-standard\n",
      "        datetime parsing, use ``pd.to_datetime`` after ``pd.read_csv``\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    thousands : str, default None\n",
      "        Thousands separator for parsing string columns to numeric.  Note that\n",
      "        this parameter is only necessary for columns stored as TEXT in Excel,\n",
      "        any numeric columns will automatically be parsed, regardless of display\n",
      "        format.\n",
      "    comment : str, default None\n",
      "        Comments out remainder of line. Pass a character or characters to this\n",
      "        argument to indicate comments in the input file. Any data between the\n",
      "        comment string and the end of the current line is ignored.\n",
      "    skip_footer : int, default 0\n",
      "        Alias of `skipfooter`.\n",
      "    \n",
      "        .. deprecated:: 0.23.0\n",
      "           Use `skipfooter` instead.\n",
      "    skipfooter : int, default 0\n",
      "        Rows at the end to skip (0-indexed).\n",
      "    convert_float : bool, default True\n",
      "        Convert integral floats to int (i.e., 1.0 --> 1). If False, all numeric\n",
      "        data will be read in as floats: Excel stores all numbers as floats\n",
      "        internally.\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    **kwds : optional\n",
      "            Optional keyword arguments can be passed to ``TextFileReader``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or dict of DataFrames\n",
      "        DataFrame from the passed in Excel file. See notes in sheet_name\n",
      "        argument for more information on when a dict of DataFrames is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    The file can be read using the file name as string or an open file object:\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0)  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1      1\n",
      "    1   string2      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    >>> pd.read_excel(open('tmp.xlsx', 'rb'),\n",
      "    ...               sheet_name='Sheet3')  # doctest: +SKIP\n",
      "       Unnamed: 0      Name  Value\n",
      "    0           0   string1      1\n",
      "    1           1   string2      2\n",
      "    2           2  #Comment      3\n",
      "    \n",
      "    Index and header can be specified via the `index_col` and `header` arguments\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=None, header=None)  # doctest: +SKIP\n",
      "         0         1      2\n",
      "    0  NaN      Name  Value\n",
      "    1  0.0   string1      1\n",
      "    2  1.0   string2      2\n",
      "    3  2.0  #Comment      3\n",
      "    \n",
      "    Column types are inferred but can be explicitly specified\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               dtype={'Name': str, 'Value': float})  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1    1.0\n",
      "    1   string2    2.0\n",
      "    2  #Comment    3.0\n",
      "    \n",
      "    True, False, and NA values, and thousands separators have defaults,\n",
      "    but can be explicitly specified, too. Supply the values you would like\n",
      "    as strings or lists of strings!\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               na_values=['string1', 'string2'])  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0       NaN      1\n",
      "    1       NaN      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    Comment lines in the excel input file can be skipped using the `comment` kwarg\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0, comment='#')  # doctest: +SKIP\n",
      "          Name  Value\n",
      "    0  string1    1.0\n",
      "    1  string2    2.0\n",
      "    2     None    NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of     Unnamed: 0                Unnamed: 1  2019-04-01 00:00:00  \\\n",
       "0     99007714                Amit Purty                  NaN   \n",
       "1     99018294             Lavanya Chapa                  NaN   \n",
       "2     99097931               Sunil Undar                  NaN   \n",
       "3     99112394              Yogesh Uppal                  NaN   \n",
       "4     99119422                SURAJ JAIN                  NaN   \n",
       "5     99111227     Jyothish Kumar Bellam                  NaN   \n",
       "6     99121343             Aditya Gaurav                  NaN   \n",
       "7     99084053         Arun Kumar Molugu                  NaN   \n",
       "8     99099398          Sivakumar Veluru                  NaN   \n",
       "9     99101824           Sathish Kumar K                  NaN   \n",
       "10    99116600            Pavan Kumar HS                  NaN   \n",
       "11    99104115          Venu Lekkalapudi                  NaN   \n",
       "12    99101891        Basappa Allannavar                  NaN   \n",
       "13      439853  Krishnaprasad Damodharan               153.00   \n",
       "14    99114625        Arumugam Duraisamy                  NaN   \n",
       "15      442223       Narender Loganathan               153.00   \n",
       "16    99088901        Gangamahesh Parasa                  NaN   \n",
       "17      436843          Arun Govindasamy               114.75   \n",
       "18      442998                 Prakash S               131.50   \n",
       "19    99101998              Bhupal Reddy                  NaN   \n",
       "20    99117567        Manish Kumar Rajak                  NaN   \n",
       "21      447490           Mahesh Yanamala               170.00   \n",
       "22    99101630      Sathish Kumar Namani                  NaN   \n",
       "23      439840            Suneetha Narni               161.50   \n",
       "24    99104131              Sneha Sharma                  NaN   \n",
       "25    99116465             Raju Sripathi                  NaN   \n",
       "\n",
       "    2019-05-01 00:00:00  2019-06-01 00:00:00  2019-07-01 00:00:00  \n",
       "0                301.75                 85.0               233.50  \n",
       "1                263.50                127.5               212.50  \n",
       "2                382.50                127.5               212.50  \n",
       "3                306.00                127.5               212.50  \n",
       "4                408.00                119.0               212.50  \n",
       "5                374.00                119.0               204.00  \n",
       "6                374.00                119.0               204.00  \n",
       "7                336.00                112.0               200.00  \n",
       "8                348.52                127.5               195.50  \n",
       "9                304.00                 88.0               192.00  \n",
       "10               336.00                128.0               192.00  \n",
       "11               299.00                120.0               177.00  \n",
       "12               320.00                128.0               166.00  \n",
       "13               147.50                143.0               163.00  \n",
       "14               360.00                120.0               160.00  \n",
       "15               178.00                124.0               153.00  \n",
       "16               357.00                118.9               144.50  \n",
       "17               101.75                140.5               136.25  \n",
       "18               198.50                133.5               134.00  \n",
       "19               352.00                 80.0               128.00  \n",
       "20               340.00                127.5               119.00  \n",
       "21               177.00                170.0               110.50  \n",
       "22               195.00                 66.0                82.00  \n",
       "23               -13.00                 98.0                78.00  \n",
       "24               328.00                  NaN                  NaN  \n",
       "25               160.00                  NaN                  NaN  >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>2019-04-01 00:00:00</th>\n",
       "      <th>2019-05-01 00:00:00</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99007714</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99018294</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99112394</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99119422</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Unnamed: 1  2019-04-01 00:00:00  2019-05-01 00:00:00  \\\n",
       "0    99007714     Amit Purty                  NaN               301.75   \n",
       "1    99018294  Lavanya Chapa                  NaN               263.50   \n",
       "2    99097931    Sunil Undar                  NaN               382.50   \n",
       "3    99112394   Yogesh Uppal                  NaN               306.00   \n",
       "4    99119422     SURAJ JAIN                  NaN               408.00   \n",
       "\n",
       "   2019-06-01 00:00:00  2019-07-01 00:00:00  \n",
       "0                 85.0                233.5  \n",
       "1                127.5                212.5  \n",
       "2                127.5                212.5  \n",
       "3                127.5                212.5  \n",
       "4                119.0                212.5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>2019-04-01 00:00:00</th>\n",
       "      <th>2019-05-01 00:00:00</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>447490</td>\n",
       "      <td>Mahesh Yanamala</td>\n",
       "      <td>170.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99101630</td>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>439840</td>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>161.5</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>99104131</td>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>99116465</td>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0            Unnamed: 1  2019-04-01 00:00:00  \\\n",
       "21      447490       Mahesh Yanamala                170.0   \n",
       "22    99101630  Sathish Kumar Namani                  NaN   \n",
       "23      439840        Suneetha Narni                161.5   \n",
       "24    99104131          Sneha Sharma                  NaN   \n",
       "25    99116465         Raju Sripathi                  NaN   \n",
       "\n",
       "    2019-05-01 00:00:00  2019-06-01 00:00:00  2019-07-01 00:00:00  \n",
       "21                177.0                170.0                110.5  \n",
       "22                195.0                 66.0                 82.0  \n",
       "23                -13.0                 98.0                 78.0  \n",
       "24                328.0                  NaN                  NaN  \n",
       "25                160.0                  NaN                  NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To know the size\n",
    "new_excel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26 entries, 0 to 25\n",
      "Data columns (total 6 columns):\n",
      "Unnamed: 0             26 non-null int64\n",
      "Unnamed: 1             26 non-null object\n",
      "2019-04-01 00:00:00    6 non-null float64\n",
      "2019-05-01 00:00:00    26 non-null float64\n",
      "2019-06-01 00:00:00    24 non-null float64\n",
      "2019-07-01 00:00:00    24 non-null float64\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#to know the datatypes of the columns\n",
    "new_excel.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>2019-04-01 00:00:00</th>\n",
       "      <th>2019-05-01 00:00:00</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.633041e+07</td>\n",
       "      <td>147.291667</td>\n",
       "      <td>278.270000</td>\n",
       "      <td>118.725000</td>\n",
       "      <td>167.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.238923e+07</td>\n",
       "      <td>20.450194</td>\n",
       "      <td>103.399284</td>\n",
       "      <td>22.199633</td>\n",
       "      <td>43.564096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.368430e+05</td>\n",
       "      <td>114.750000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.901036e+07</td>\n",
       "      <td>136.875000</td>\n",
       "      <td>195.875000</td>\n",
       "      <td>117.175000</td>\n",
       "      <td>135.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.910173e+07</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>171.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.911210e+07</td>\n",
       "      <td>159.375000</td>\n",
       "      <td>351.130000</td>\n",
       "      <td>127.625000</td>\n",
       "      <td>204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.912134e+07</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>233.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  2019-04-01 00:00:00  2019-05-01 00:00:00  \\\n",
       "count  2.600000e+01             6.000000            26.000000   \n",
       "mean   7.633041e+07           147.291667           278.270000   \n",
       "std    4.238923e+07            20.450194           103.399284   \n",
       "min    4.368430e+05           114.750000           -13.000000   \n",
       "25%    9.901036e+07           136.875000           195.875000   \n",
       "50%    9.910173e+07           153.000000           313.000000   \n",
       "75%    9.911210e+07           159.375000           351.130000   \n",
       "max    9.912134e+07           170.000000           408.000000   \n",
       "\n",
       "       2019-06-01 00:00:00  2019-07-01 00:00:00  \n",
       "count            24.000000            24.000000  \n",
       "mean            118.725000           167.593750  \n",
       "std              22.199633            43.564096  \n",
       "min              66.000000            78.000000  \n",
       "25%             117.175000           135.687500  \n",
       "50%             122.000000           171.500000  \n",
       "75%             127.625000           204.000000  \n",
       "max             170.000000           233.500000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.describe()\n",
    "#Will give statistical info of the numeric columns alone. Not the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([       'Unnamed: 0',        'Unnamed: 1', 2019-04-01 00:00:00,\n",
       "       2019-05-01 00:00:00, 2019-06-01 00:00:00, 2019-07-01 00:00:00],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.columns\n",
    "#here columns is an attribute like shape. It is not a method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Unnamed: 1',\n",
       " datetime.datetime(2019, 4, 1, 0, 0),\n",
       " datetime.datetime(2019, 5, 1, 0, 0),\n",
       " datetime.datetime(2019, 6, 1, 0, 0),\n",
       " datetime.datetime(2019, 7, 1, 0, 0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.columns.tolist()\n",
    "#Column is also an attribute like shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>2019-04-01 00:00:00</th>\n",
       "      <th>2019-05-01 00:00:00</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 1  2019-04-01 00:00:00  2019-05-01 00:00:00  \\\n",
       "0        False       False                 True                False   \n",
       "1        False       False                 True                False   \n",
       "2        False       False                 True                False   \n",
       "3        False       False                 True                False   \n",
       "4        False       False                 True                False   \n",
       "5        False       False                 True                False   \n",
       "6        False       False                 True                False   \n",
       "7        False       False                 True                False   \n",
       "8        False       False                 True                False   \n",
       "9        False       False                 True                False   \n",
       "10       False       False                 True                False   \n",
       "11       False       False                 True                False   \n",
       "12       False       False                 True                False   \n",
       "13       False       False                False                False   \n",
       "14       False       False                 True                False   \n",
       "15       False       False                False                False   \n",
       "16       False       False                 True                False   \n",
       "17       False       False                False                False   \n",
       "18       False       False                False                False   \n",
       "19       False       False                 True                False   \n",
       "20       False       False                 True                False   \n",
       "21       False       False                False                False   \n",
       "22       False       False                 True                False   \n",
       "23       False       False                False                False   \n",
       "24       False       False                 True                False   \n",
       "25       False       False                 True                False   \n",
       "\n",
       "    2019-06-01 00:00:00  2019-07-01 00:00:00  \n",
       "0                 False                False  \n",
       "1                 False                False  \n",
       "2                 False                False  \n",
       "3                 False                False  \n",
       "4                 False                False  \n",
       "5                 False                False  \n",
       "6                 False                False  \n",
       "7                 False                False  \n",
       "8                 False                False  \n",
       "9                 False                False  \n",
       "10                False                False  \n",
       "11                False                False  \n",
       "12                False                False  \n",
       "13                False                False  \n",
       "14                False                False  \n",
       "15                False                False  \n",
       "16                False                False  \n",
       "17                False                False  \n",
       "18                False                False  \n",
       "19                False                False  \n",
       "20                False                False  \n",
       "21                False                False  \n",
       "22                False                False  \n",
       "23                False                False  \n",
       "24                 True                 True  \n",
       "25                 True                 True  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "new_excel.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              0\n",
       "Unnamed: 1              0\n",
       "2019-04-01 00:00:00    20\n",
       "2019-05-01 00:00:00     0\n",
       "2019-06-01 00:00:00     2\n",
       "2019-07-01 00:00:00     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.isnull().sum()\n",
    "#this is what is normally used to identify nulls as it gives the count of nulls column-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list1=[True,False,True]\n",
    "list1 = pd.Series([True,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>April Month</th>\n",
       "      <th>May Month</th>\n",
       "      <th>June Month</th>\n",
       "      <th>July Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99007714</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99018294</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99112394</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99119422</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99111227</td>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99121343</td>\n",
       "      <td>Aditya Gaurav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99084053</td>\n",
       "      <td>Arun Kumar Molugu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99099398</td>\n",
       "      <td>Sivakumar Veluru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.52</td>\n",
       "      <td>127.5</td>\n",
       "      <td>195.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99101824</td>\n",
       "      <td>Sathish Kumar K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99116600</td>\n",
       "      <td>Pavan Kumar HS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>99104115</td>\n",
       "      <td>Venu Lekkalapudi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>99101891</td>\n",
       "      <td>Basappa Allannavar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99114625</td>\n",
       "      <td>Arumugam Duraisamy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>99088901</td>\n",
       "      <td>Gangamahesh Parasa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.00</td>\n",
       "      <td>118.9</td>\n",
       "      <td>144.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>99101998</td>\n",
       "      <td>Bhupal Reddy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>99117567</td>\n",
       "      <td>Manish Kumar Rajak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99101630</td>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>99104131</td>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>99116465</td>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMPID                   Name  April Month  May Month  June Month  \\\n",
       "0   99007714             Amit Purty          NaN     301.75        85.0   \n",
       "1   99018294          Lavanya Chapa          NaN     263.50       127.5   \n",
       "2   99097931            Sunil Undar          NaN     382.50       127.5   \n",
       "3   99112394           Yogesh Uppal          NaN     306.00       127.5   \n",
       "4   99119422             SURAJ JAIN          NaN     408.00       119.0   \n",
       "5   99111227  Jyothish Kumar Bellam          NaN     374.00       119.0   \n",
       "6   99121343          Aditya Gaurav          NaN     374.00       119.0   \n",
       "7   99084053      Arun Kumar Molugu          NaN     336.00       112.0   \n",
       "8   99099398       Sivakumar Veluru          NaN     348.52       127.5   \n",
       "9   99101824        Sathish Kumar K          NaN     304.00        88.0   \n",
       "10  99116600         Pavan Kumar HS          NaN     336.00       128.0   \n",
       "11  99104115       Venu Lekkalapudi          NaN     299.00       120.0   \n",
       "12  99101891     Basappa Allannavar          NaN     320.00       128.0   \n",
       "14  99114625     Arumugam Duraisamy          NaN     360.00       120.0   \n",
       "16  99088901     Gangamahesh Parasa          NaN     357.00       118.9   \n",
       "19  99101998           Bhupal Reddy          NaN     352.00        80.0   \n",
       "20  99117567     Manish Kumar Rajak          NaN     340.00       127.5   \n",
       "22  99101630   Sathish Kumar Namani          NaN     195.00        66.0   \n",
       "24  99104131           Sneha Sharma          NaN     328.00         NaN   \n",
       "25  99116465          Raju Sripathi          NaN     160.00         NaN   \n",
       "\n",
       "    July Month  \n",
       "0        233.5  \n",
       "1        212.5  \n",
       "2        212.5  \n",
       "3        212.5  \n",
       "4        212.5  \n",
       "5        204.0  \n",
       "6        204.0  \n",
       "7        200.0  \n",
       "8        195.5  \n",
       "9        192.0  \n",
       "10       192.0  \n",
       "11       177.0  \n",
       "12       166.0  \n",
       "14       160.0  \n",
       "16       144.5  \n",
       "19       128.0  \n",
       "20       119.0  \n",
       "22        82.0  \n",
       "24         NaN  \n",
       "25         NaN  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to find the rows whwere we have null values. The above is for columns\n",
    "new_excel[new_excel.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2019-04-01 00:00:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '2019-04-01 00:00:00'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b59375624869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#If i want to get one column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnew_excel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'2019-04-01 00:00:00'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '2019-04-01 00:00:00'"
     ]
    }
   ],
   "source": [
    "#If i want to get one column\n",
    "new_excel['2019-04-01 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Athens\n",
       "1         Athens\n",
       "2         Athens\n",
       "3            NaN\n",
       "4         Athens\n",
       "5         Athens\n",
       "6         Athens\n",
       "7         Athens\n",
       "8         Athens\n",
       "9         Athens\n",
       "10        Athens\n",
       "11        Athens\n",
       "12        Athens\n",
       "13        Athens\n",
       "14        Athens\n",
       "15        Athens\n",
       "16        Athens\n",
       "17        Athens\n",
       "18        Athens\n",
       "19        Athens\n",
       "20        Athens\n",
       "21        Athens\n",
       "22        Athens\n",
       "23        Athens\n",
       "24        Athens\n",
       "25        Athens\n",
       "26        Athens\n",
       "27        Athens\n",
       "28        Athens\n",
       "29        Athens\n",
       "          ...   \n",
       "29187    Beijing\n",
       "29188    Beijing\n",
       "29189    Beijing\n",
       "29190    Beijing\n",
       "29191    Beijing\n",
       "29192    Beijing\n",
       "29193    Beijing\n",
       "29194    Beijing\n",
       "29195    Beijing\n",
       "29196    Beijing\n",
       "29197    Beijing\n",
       "29198    Beijing\n",
       "29199    Beijing\n",
       "29200    Beijing\n",
       "29201    Beijing\n",
       "29202    Beijing\n",
       "29203    Beijing\n",
       "29204    Beijing\n",
       "29205    Beijing\n",
       "29206    Beijing\n",
       "29207    Beijing\n",
       "29208    Beijing\n",
       "29209    Beijing\n",
       "29210    Beijing\n",
       "29211    Beijing\n",
       "29212    Beijing\n",
       "29213    Beijing\n",
       "29214    Beijing\n",
       "29215    Beijing\n",
       "29216    Beijing\n",
       "Name: City, Length: 29217, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get more than one columns will have to pass both the column in a list\n",
    "#olympic_data[[\"city\",'sport']].head()\n",
    "# only for one column olympic_data.city\n",
    "#new_excel.info()\n",
    "olympic_data.head()\n",
    "olympic_data[[\"City\",\"Sport\"]].head()\n",
    "olympic_data.City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel = pd.read_excel(\"C:/Users/tin2419/Desktop/Time Report.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26 entries, 0 to 25\n",
      "Data columns (total 6 columns):\n",
      "EMPID    26 non-null int64\n",
      "Name     26 non-null object\n",
      "Col1     6 non-null float64\n",
      "Col2     26 non-null float64\n",
      "Col3     24 non-null float64\n",
      "Col4     24 non-null float64\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "new_excel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99007714\n",
       "1    99018294\n",
       "2    99097931\n",
       "3    99112394\n",
       "4    99119422\n",
       "Name: EMPID, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.EMPID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.5</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMPID         Name  Col1   Col2   Col3   Col4\n",
       "2  99097931  Sunil Undar   NaN  382.5  127.5  212.5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_excel[new_excel[\"Col2\"]==301.75]\n",
    "#new_excel[(new_excel[\"Col2\"]==301.75) | (new_excel[\"Col3\"]==127.5)]\n",
    "new_excel[(new_excel[\"Col2\"]==382.5) & (new_excel[\"Col3\"]==127.5)]\n",
    "#The first one is for 'OR' and the second for 'AND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel[(new_excel[\"Col2\"]==301.75) | (new_excel[\"Col3\"]==127.5)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel[(new_excel[\"Col2\"]==301.75) | (new_excel[\"Col3\"]==127.5)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "5      True\n",
       "6      True\n",
       "7      True\n",
       "8      True\n",
       "9      True\n",
       "10     True\n",
       "11     True\n",
       "12     True\n",
       "13    False\n",
       "14     True\n",
       "15    False\n",
       "16     True\n",
       "17    False\n",
       "18    False\n",
       "19     True\n",
       "20     True\n",
       "21    False\n",
       "22     True\n",
       "23    False\n",
       "24     True\n",
       "25     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.isnull().any(axis=1)\n",
    "#How many values in the colums are null. it returns even if one column is null. It goes row wise. So for each row it will \n",
    "#tell us if any of the column is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99007714</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99018294</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99112394</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99119422</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99111227</td>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99121343</td>\n",
       "      <td>Aditya Gaurav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99084053</td>\n",
       "      <td>Arun Kumar Molugu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99099398</td>\n",
       "      <td>Sivakumar Veluru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.52</td>\n",
       "      <td>127.5</td>\n",
       "      <td>195.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99101824</td>\n",
       "      <td>Sathish Kumar K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99116600</td>\n",
       "      <td>Pavan Kumar HS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>99104115</td>\n",
       "      <td>Venu Lekkalapudi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>99101891</td>\n",
       "      <td>Basappa Allannavar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99114625</td>\n",
       "      <td>Arumugam Duraisamy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>99088901</td>\n",
       "      <td>Gangamahesh Parasa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.00</td>\n",
       "      <td>118.9</td>\n",
       "      <td>144.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>99101998</td>\n",
       "      <td>Bhupal Reddy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>99117567</td>\n",
       "      <td>Manish Kumar Rajak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99101630</td>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>99104131</td>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>99116465</td>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMPID                   Name  Col1    Col2   Col3   Col4\n",
       "0   99007714             Amit Purty   NaN  301.75   85.0  233.5\n",
       "1   99018294          Lavanya Chapa   NaN  263.50  127.5  212.5\n",
       "2   99097931            Sunil Undar   NaN  382.50  127.5  212.5\n",
       "3   99112394           Yogesh Uppal   NaN  306.00  127.5  212.5\n",
       "4   99119422             SURAJ JAIN   NaN  408.00  119.0  212.5\n",
       "5   99111227  Jyothish Kumar Bellam   NaN  374.00  119.0  204.0\n",
       "6   99121343          Aditya Gaurav   NaN  374.00  119.0  204.0\n",
       "7   99084053      Arun Kumar Molugu   NaN  336.00  112.0  200.0\n",
       "8   99099398       Sivakumar Veluru   NaN  348.52  127.5  195.5\n",
       "9   99101824        Sathish Kumar K   NaN  304.00   88.0  192.0\n",
       "10  99116600         Pavan Kumar HS   NaN  336.00  128.0  192.0\n",
       "11  99104115       Venu Lekkalapudi   NaN  299.00  120.0  177.0\n",
       "12  99101891     Basappa Allannavar   NaN  320.00  128.0  166.0\n",
       "14  99114625     Arumugam Duraisamy   NaN  360.00  120.0  160.0\n",
       "16  99088901     Gangamahesh Parasa   NaN  357.00  118.9  144.5\n",
       "19  99101998           Bhupal Reddy   NaN  352.00   80.0  128.0\n",
       "20  99117567     Manish Kumar Rajak   NaN  340.00  127.5  119.0\n",
       "22  99101630   Sathish Kumar Namani   NaN  195.00   66.0   82.0\n",
       "24  99104131           Sneha Sharma   NaN  328.00    NaN    NaN\n",
       "25  99116465          Raju Sripathi   NaN  160.00    NaN    NaN"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel[new_excel.isnull().any(axis=1)]\n",
    "#here axis = 1, it says that check the columns in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EMPID, Name, Col1, Col2, Col3, Col4]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel[new_excel.isnull().all(axis=1)]\n",
    "#To find rows where all the values are null\n",
    "#For this we will never use axis = 0, because we are always checking the columns in the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where we need to use axis = 0\n",
    "#To drop rows that have null values\n",
    "#new_excel.dropna(how=\"any\",axis=0)\n",
    "new_excel = pd.read_excel(\"C:/Users/tin2419/Desktop/Time Report.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>439853</td>\n",
       "      <td>Krishnaprasad Damodharan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.0</td>\n",
       "      <td>163.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>442223</td>\n",
       "      <td>Narender Loganathan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>436843</td>\n",
       "      <td>Arun Govindasamy</td>\n",
       "      <td>114.75</td>\n",
       "      <td>101.75</td>\n",
       "      <td>140.5</td>\n",
       "      <td>136.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>442998</td>\n",
       "      <td>Prakash S</td>\n",
       "      <td>131.50</td>\n",
       "      <td>198.50</td>\n",
       "      <td>133.5</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>447490</td>\n",
       "      <td>Mahesh Yanamala</td>\n",
       "      <td>170.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>439840</td>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>161.50</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     EMPID                      Name    Col1    Col2   Col3    Col4\n",
       "13  439853  Krishnaprasad Damodharan  153.00  147.50  143.0  163.00\n",
       "15  442223       Narender Loganathan  153.00  178.00  124.0  153.00\n",
       "17  436843          Arun Govindasamy  114.75  101.75  140.5  136.25\n",
       "18  442998                 Prakash S  131.50  198.50  133.5  134.00\n",
       "21  447490           Mahesh Yanamala  170.00  177.00  170.0  110.50\n",
       "23  439840            Suneetha Narni  161.50  -13.00   98.0   78.00"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.dropna(how=\"any\",axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99007714</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99018294</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99112394</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99119422</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99111227</td>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99121343</td>\n",
       "      <td>Aditya Gaurav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99084053</td>\n",
       "      <td>Arun Kumar Molugu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99099398</td>\n",
       "      <td>Sivakumar Veluru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.52</td>\n",
       "      <td>127.5</td>\n",
       "      <td>195.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99101824</td>\n",
       "      <td>Sathish Kumar K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99116600</td>\n",
       "      <td>Pavan Kumar HS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>99104115</td>\n",
       "      <td>Venu Lekkalapudi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>99101891</td>\n",
       "      <td>Basappa Allannavar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>439853</td>\n",
       "      <td>Krishnaprasad Damodharan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.0</td>\n",
       "      <td>163.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99114625</td>\n",
       "      <td>Arumugam Duraisamy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>442223</td>\n",
       "      <td>Narender Loganathan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>99088901</td>\n",
       "      <td>Gangamahesh Parasa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.00</td>\n",
       "      <td>118.9</td>\n",
       "      <td>144.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>436843</td>\n",
       "      <td>Arun Govindasamy</td>\n",
       "      <td>114.75</td>\n",
       "      <td>101.75</td>\n",
       "      <td>140.5</td>\n",
       "      <td>136.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>442998</td>\n",
       "      <td>Prakash S</td>\n",
       "      <td>131.50</td>\n",
       "      <td>198.50</td>\n",
       "      <td>133.5</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>99101998</td>\n",
       "      <td>Bhupal Reddy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>128.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>99117567</td>\n",
       "      <td>Manish Kumar Rajak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>119.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>447490</td>\n",
       "      <td>Mahesh Yanamala</td>\n",
       "      <td>170.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99101630</td>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>439840</td>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>161.50</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>99104131</td>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>99116465</td>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>99116466</td>\n",
       "      <td>Rajesh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMPID                      Name    Col1    Col2   Col3    Col4\n",
       "0   99007714                Amit Purty     NaN  301.75   85.0  233.50\n",
       "1   99018294             Lavanya Chapa     NaN  263.50  127.5  212.50\n",
       "2   99097931               Sunil Undar     NaN  382.50  127.5  212.50\n",
       "3   99112394              Yogesh Uppal     NaN  306.00  127.5  212.50\n",
       "4   99119422                SURAJ JAIN     NaN  408.00  119.0  212.50\n",
       "5   99111227     Jyothish Kumar Bellam     NaN  374.00  119.0  204.00\n",
       "6   99121343             Aditya Gaurav     NaN  374.00  119.0  204.00\n",
       "7   99084053         Arun Kumar Molugu     NaN  336.00  112.0  200.00\n",
       "8   99099398          Sivakumar Veluru     NaN  348.52  127.5  195.50\n",
       "9   99101824           Sathish Kumar K     NaN  304.00   88.0  192.00\n",
       "10  99116600            Pavan Kumar HS     NaN  336.00  128.0  192.00\n",
       "11  99104115          Venu Lekkalapudi     NaN  299.00  120.0  177.00\n",
       "12  99101891        Basappa Allannavar     NaN  320.00  128.0  166.00\n",
       "13    439853  Krishnaprasad Damodharan  153.00  147.50  143.0  163.00\n",
       "14  99114625        Arumugam Duraisamy     NaN  360.00  120.0  160.00\n",
       "15    442223       Narender Loganathan  153.00  178.00  124.0  153.00\n",
       "16  99088901        Gangamahesh Parasa     NaN  357.00  118.9  144.50\n",
       "17    436843          Arun Govindasamy  114.75  101.75  140.5  136.25\n",
       "18    442998                 Prakash S  131.50  198.50  133.5  134.00\n",
       "19  99101998              Bhupal Reddy     NaN  352.00   80.0  128.00\n",
       "20  99117567        Manish Kumar Rajak     NaN  340.00  127.5  119.00\n",
       "21    447490           Mahesh Yanamala  170.00  177.00  170.0  110.50\n",
       "22  99101630      Sathish Kumar Namani     NaN  195.00   66.0   82.00\n",
       "23    439840            Suneetha Narni  161.50  -13.00   98.0   78.00\n",
       "24  99104131              Sneha Sharma     NaN  328.00    NaN     NaN\n",
       "25  99116465             Raju Sripathi     NaN  160.00    NaN     NaN\n",
       "26  99116466                    Rajesh     NaN     NaN    NaN     NaN"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.dropna(how=\"all\",axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel_drop = new_excel.dropna(how=\"all\",axis=0,inplace=True)\n",
    "#Once we drop it using inplace, then no point assigning it. So the above statement is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel_drop\n",
    "#will give us nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method dropna in module pandas.core.frame:\n",
      "\n",
      "dropna(axis=0, how='any', thresh=None, subset=None, inplace=False) method of pandas.core.frame.DataFrame instance\n",
      "    Remove missing values.\n",
      "    \n",
      "    See the :ref:`User Guide <missing_data>` for more on which values are\n",
      "    considered missing, and how to work with missing data.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Determine if rows or columns which contain missing values are\n",
      "        removed.\n",
      "    \n",
      "        * 0, or 'index' : Drop rows which contain missing values.\n",
      "        * 1, or 'columns' : Drop columns which contain missing value.\n",
      "    \n",
      "        .. deprecated:: 0.23.0\n",
      "    \n",
      "           Pass tuple or list to drop on multiple axes.\n",
      "           Only a single axis is allowed.\n",
      "    \n",
      "    how : {'any', 'all'}, default 'any'\n",
      "        Determine if row or column is removed from DataFrame, when we have\n",
      "        at least one NA or all NA.\n",
      "    \n",
      "        * 'any' : If any NA values are present, drop that row or column.\n",
      "        * 'all' : If all values are NA, drop that row or column.\n",
      "    \n",
      "    thresh : int, optional\n",
      "        Require that many non-NA values.\n",
      "    subset : array-like, optional\n",
      "        Labels along other axis to consider, e.g. if you are dropping rows\n",
      "        these would be a list of columns to include.\n",
      "    inplace : bool, default False\n",
      "        If True, do operation inplace and return None.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        DataFrame with NA entries dropped from it.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.isna: Indicate missing values.\n",
      "    DataFrame.notna : Indicate existing (non-missing) values.\n",
      "    DataFrame.fillna : Replace missing values.\n",
      "    Series.dropna : Drop missing values.\n",
      "    Index.dropna : Drop missing indices.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      "    ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      "    ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      "    ...                             pd.NaT]})\n",
      "    >>> df\n",
      "           name        toy       born\n",
      "    0    Alfred        NaN        NaT\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Drop the rows where at least one element is missing.\n",
      "    \n",
      "    >>> df.dropna()\n",
      "         name        toy       born\n",
      "    1  Batman  Batmobile 1940-04-25\n",
      "    \n",
      "    Drop the columns where at least one element is missing.\n",
      "    \n",
      "    >>> df.dropna(axis='columns')\n",
      "           name\n",
      "    0    Alfred\n",
      "    1    Batman\n",
      "    2  Catwoman\n",
      "    \n",
      "    Drop the rows where all elements are missing.\n",
      "    \n",
      "    >>> df.dropna(how='all')\n",
      "           name        toy       born\n",
      "    0    Alfred        NaN        NaT\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Keep only the rows with at least 2 non-NA values.\n",
      "    \n",
      "    >>> df.dropna(thresh=2)\n",
      "           name        toy       born\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Define in which columns to look for missing values.\n",
      "    \n",
      "    >>> df.dropna(subset=['name', 'born'])\n",
      "           name        toy       born\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    \n",
      "    Keep the DataFrame with valid entries in the same variable.\n",
      "    \n",
      "    >>> df.dropna(inplace=True)\n",
      "    >>> df\n",
      "         name        toy       born\n",
      "    1  Batman  Batmobile 1940-04-25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(new_excel.dropna)\n",
    "# Remember to use the object name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel = pd.read_excel(\"C:/Users/tin2419/Desktop/Time Report.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel_drop = new_excel.dropna(how=\"any\",axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>439853</td>\n",
       "      <td>Krishnaprasad Damodharan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.0</td>\n",
       "      <td>163.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>442223</td>\n",
       "      <td>Narender Loganathan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>436843</td>\n",
       "      <td>Arun Govindasamy</td>\n",
       "      <td>114.75</td>\n",
       "      <td>101.75</td>\n",
       "      <td>140.5</td>\n",
       "      <td>136.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>442998</td>\n",
       "      <td>Prakash S</td>\n",
       "      <td>131.50</td>\n",
       "      <td>198.50</td>\n",
       "      <td>133.5</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>447490</td>\n",
       "      <td>Mahesh Yanamala</td>\n",
       "      <td>170.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>439840</td>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>161.50</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     EMPID                      Name    Col1    Col2   Col3    Col4\n",
       "13  439853  Krishnaprasad Damodharan  153.00  147.50  143.0  163.00\n",
       "15  442223       Narender Loganathan  153.00  178.00  124.0  153.00\n",
       "17  436843          Arun Govindasamy  114.75  101.75  140.5  136.25\n",
       "18  442998                 Prakash S  131.50  198.50  133.5  134.00\n",
       "21  447490           Mahesh Yanamala  170.00  177.00  170.0  110.50\n",
       "23  439840            Suneetha Narni  161.50  -13.00   98.0   78.00"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel = new_excel.dropna(how=\"any\",axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'dropna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-a1c78b124838>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_excel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_excel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"any\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dropna'"
     ]
    }
   ],
   "source": [
    "new_excel = new_excel.dropna(how=\"any\",axis=1)\n",
    "#here axis =1 means drop the column. please make note. axis means what you want to drop - here it is column\n",
    "#the other one was how we want to search - this has the opposite meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'isnull'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-67ceb595492d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#If i want to fill the null values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnew_excel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_excel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'isnull'"
     ]
    }
   ],
   "source": [
    "#If i want to fill the null values \n",
    "new_excel[new_excel.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-86cd522a2365>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_excel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "new_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-de1edc386af2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#In the Name column replace nulls with No Name and in the April Month column, replace nulls with No Value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#import numpy as np\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mnew_excel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"May Month\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#using numpy function (np). Wherever in the city column, one finds null, fill it using the mode value - np.mode()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'mode'"
     ]
    }
   ],
   "source": [
    "#new_excel = pd.read_excel(\"C:/Users/tin2419/Desktop/DSFiles/timereport.xlsx\", skiprows=3)\n",
    "#new_excel.head()\n",
    "#new_excel[\"Name\"].fillna(\"Sunil\").head()\n",
    "#Fill using sunil wherever it is null\n",
    "#new_excel.fillna({\"Name\":\"No Name\",\"April Month\":\"No Value\"})\n",
    "#In the Name column replace nulls with No Name and in the April Month column, replace nulls with No Value\n",
    "#import numpy as np\n",
    "new_excel[\"May Month\"].fillna(np.mode())\n",
    "#using numpy function (np). Wherever in the city column, one finds null, fill it using the mode value - np.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Amit Purty\n",
       "1    Lavanya Chapa\n",
       "2      Sunil Undar\n",
       "3     Yogesh Uppal\n",
       "4       SURAJ JAIN\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel[\"Name\"].fillna(\"Amit Purty\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99007714</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99018294</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99112394</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99119422</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMPID           Name  Col1    Col2   Col3   Col4\n",
       "0  99007714     Amit Purty   NaN  301.75   85.0  233.5\n",
       "1  99018294  Lavanya Chapa   NaN  263.50  127.5  212.5\n",
       "2  99097931    Sunil Undar   NaN  382.50  127.5  212.5\n",
       "3  99112394   Yogesh Uppal   NaN  306.00  127.5  212.5\n",
       "4  99119422     SURAJ JAIN   NaN  408.00  119.0  212.5"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99101630</td>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>439840</td>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>161.5</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>99104131</td>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>99116465</td>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>99116466</td>\n",
       "      <td>Rajesh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMPID                  Name   Col1   Col2  Col3  Col4\n",
       "22  99101630  Sathish Kumar Namani    NaN  195.0  66.0  82.0\n",
       "23    439840        Suneetha Narni  161.5  -13.0  98.0  78.0\n",
       "24  99104131          Sneha Sharma    NaN  328.0   NaN   NaN\n",
       "25  99116465         Raju Sripathi    NaN  160.0   NaN   NaN\n",
       "26  99116466                Rajesh    NaN    NaN   NaN   NaN"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc - label based access (column based access) and iloc - integer based access  (row based access)\n",
    "new_excel = pd.read_excel(\"C:/Users/tin2419/Desktop/Time Report.xlsx\",index_col =\"Name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amit Purty</th>\n",
       "      <td>99007714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lavanya Chapa</th>\n",
       "      <td>99018294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunil Undar</th>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yogesh Uppal</th>\n",
       "      <td>99112394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SURAJ JAIN</th>\n",
       "      <td>99119422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EMPID  Col1    Col2   Col3   Col4\n",
       "Name                                               \n",
       "Amit Purty     99007714   NaN  301.75   85.0  233.5\n",
       "Lavanya Chapa  99018294   NaN  263.50  127.5  212.5\n",
       "Sunil Undar    99097931   NaN  382.50  127.5  212.5\n",
       "Yogesh Uppal   99112394   NaN  306.00  127.5  212.5\n",
       "SURAJ JAIN     99119422   NaN  408.00  119.0  212.5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the index is changed to name and now the Name column is no longer part of the data\n",
    "new_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>99007714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>99018294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>99112394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>99119422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>99111227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aditya Gaurav</td>\n",
       "      <td>99121343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arun Kumar Molugu</td>\n",
       "      <td>99084053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sivakumar Veluru</td>\n",
       "      <td>99099398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.52</td>\n",
       "      <td>127.5</td>\n",
       "      <td>195.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sathish Kumar K</td>\n",
       "      <td>99101824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pavan Kumar HS</td>\n",
       "      <td>99116600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Venu Lekkalapudi</td>\n",
       "      <td>99104115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Basappa Allannavar</td>\n",
       "      <td>99101891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Krishnaprasad Damodharan</td>\n",
       "      <td>439853</td>\n",
       "      <td>153.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.0</td>\n",
       "      <td>163.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Arumugam Duraisamy</td>\n",
       "      <td>99114625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Narender Loganathan</td>\n",
       "      <td>442223</td>\n",
       "      <td>153.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gangamahesh Parasa</td>\n",
       "      <td>99088901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.00</td>\n",
       "      <td>118.9</td>\n",
       "      <td>144.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Arun Govindasamy</td>\n",
       "      <td>436843</td>\n",
       "      <td>114.75</td>\n",
       "      <td>101.75</td>\n",
       "      <td>140.5</td>\n",
       "      <td>136.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Prakash S</td>\n",
       "      <td>442998</td>\n",
       "      <td>131.50</td>\n",
       "      <td>198.50</td>\n",
       "      <td>133.5</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bhupal Reddy</td>\n",
       "      <td>99101998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>128.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Manish Kumar Rajak</td>\n",
       "      <td>99117567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>119.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mahesh Yanamala</td>\n",
       "      <td>447490</td>\n",
       "      <td>170.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>99101630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>439840</td>\n",
       "      <td>161.50</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>99104131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>99116465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Rajesh</td>\n",
       "      <td>99116466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name     EMPID    Col1    Col2   Col3    Col4\n",
       "0                 Amit Purty  99007714     NaN  301.75   85.0  233.50\n",
       "1              Lavanya Chapa  99018294     NaN  263.50  127.5  212.50\n",
       "2                Sunil Undar  99097931     NaN  382.50  127.5  212.50\n",
       "3               Yogesh Uppal  99112394     NaN  306.00  127.5  212.50\n",
       "4                 SURAJ JAIN  99119422     NaN  408.00  119.0  212.50\n",
       "5      Jyothish Kumar Bellam  99111227     NaN  374.00  119.0  204.00\n",
       "6              Aditya Gaurav  99121343     NaN  374.00  119.0  204.00\n",
       "7          Arun Kumar Molugu  99084053     NaN  336.00  112.0  200.00\n",
       "8           Sivakumar Veluru  99099398     NaN  348.52  127.5  195.50\n",
       "9            Sathish Kumar K  99101824     NaN  304.00   88.0  192.00\n",
       "10            Pavan Kumar HS  99116600     NaN  336.00  128.0  192.00\n",
       "11          Venu Lekkalapudi  99104115     NaN  299.00  120.0  177.00\n",
       "12        Basappa Allannavar  99101891     NaN  320.00  128.0  166.00\n",
       "13  Krishnaprasad Damodharan    439853  153.00  147.50  143.0  163.00\n",
       "14        Arumugam Duraisamy  99114625     NaN  360.00  120.0  160.00\n",
       "15       Narender Loganathan    442223  153.00  178.00  124.0  153.00\n",
       "16        Gangamahesh Parasa  99088901     NaN  357.00  118.9  144.50\n",
       "17          Arun Govindasamy    436843  114.75  101.75  140.5  136.25\n",
       "18                 Prakash S    442998  131.50  198.50  133.5  134.00\n",
       "19              Bhupal Reddy  99101998     NaN  352.00   80.0  128.00\n",
       "20        Manish Kumar Rajak  99117567     NaN  340.00  127.5  119.00\n",
       "21           Mahesh Yanamala    447490  170.00  177.00  170.0  110.50\n",
       "22      Sathish Kumar Namani  99101630     NaN  195.00   66.0   82.00\n",
       "23            Suneetha Narni    439840  161.50  -13.00   98.0   78.00\n",
       "24              Sneha Sharma  99104131     NaN  328.00    NaN     NaN\n",
       "25             Raju Sripathi  99116465     NaN  160.00    NaN     NaN\n",
       "26                    Rajesh  99116466     NaN     NaN    NaN     NaN"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To change index back. Now name is no longer part of the index\n",
    "new_excel.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amit Purty</th>\n",
       "      <td>99007714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lavanya Chapa</th>\n",
       "      <td>99018294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunil Undar</th>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yogesh Uppal</th>\n",
       "      <td>99112394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SURAJ JAIN</th>\n",
       "      <td>99119422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jyothish Kumar Bellam</th>\n",
       "      <td>99111227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aditya Gaurav</th>\n",
       "      <td>99121343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arun Kumar Molugu</th>\n",
       "      <td>99084053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sivakumar Veluru</th>\n",
       "      <td>99099398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.52</td>\n",
       "      <td>127.5</td>\n",
       "      <td>195.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sathish Kumar K</th>\n",
       "      <td>99101824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pavan Kumar HS</th>\n",
       "      <td>99116600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venu Lekkalapudi</th>\n",
       "      <td>99104115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basappa Allannavar</th>\n",
       "      <td>99101891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Krishnaprasad Damodharan</th>\n",
       "      <td>439853</td>\n",
       "      <td>153.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.0</td>\n",
       "      <td>163.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arumugam Duraisamy</th>\n",
       "      <td>99114625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Narender Loganathan</th>\n",
       "      <td>442223</td>\n",
       "      <td>153.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gangamahesh Parasa</th>\n",
       "      <td>99088901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.00</td>\n",
       "      <td>118.9</td>\n",
       "      <td>144.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arun Govindasamy</th>\n",
       "      <td>436843</td>\n",
       "      <td>114.75</td>\n",
       "      <td>101.75</td>\n",
       "      <td>140.5</td>\n",
       "      <td>136.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prakash S</th>\n",
       "      <td>442998</td>\n",
       "      <td>131.50</td>\n",
       "      <td>198.50</td>\n",
       "      <td>133.5</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bhupal Reddy</th>\n",
       "      <td>99101998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>128.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manish Kumar Rajak</th>\n",
       "      <td>99117567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>119.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mahesh Yanamala</th>\n",
       "      <td>447490</td>\n",
       "      <td>170.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sathish Kumar Namani</th>\n",
       "      <td>99101630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suneetha Narni</th>\n",
       "      <td>439840</td>\n",
       "      <td>161.50</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sneha Sharma</th>\n",
       "      <td>99104131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raju Sripathi</th>\n",
       "      <td>99116465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rajesh</th>\n",
       "      <td>99116466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             EMPID    Col1    Col2   Col3    Col4\n",
       "Name                                                             \n",
       "Amit Purty                99007714     NaN  301.75   85.0  233.50\n",
       "Lavanya Chapa             99018294     NaN  263.50  127.5  212.50\n",
       "Sunil Undar               99097931     NaN  382.50  127.5  212.50\n",
       "Yogesh Uppal              99112394     NaN  306.00  127.5  212.50\n",
       "SURAJ JAIN                99119422     NaN  408.00  119.0  212.50\n",
       "Jyothish Kumar Bellam     99111227     NaN  374.00  119.0  204.00\n",
       "Aditya Gaurav             99121343     NaN  374.00  119.0  204.00\n",
       "Arun Kumar Molugu         99084053     NaN  336.00  112.0  200.00\n",
       "Sivakumar Veluru          99099398     NaN  348.52  127.5  195.50\n",
       "Sathish Kumar K           99101824     NaN  304.00   88.0  192.00\n",
       "Pavan Kumar HS            99116600     NaN  336.00  128.0  192.00\n",
       "Venu Lekkalapudi          99104115     NaN  299.00  120.0  177.00\n",
       "Basappa Allannavar        99101891     NaN  320.00  128.0  166.00\n",
       "Krishnaprasad Damodharan    439853  153.00  147.50  143.0  163.00\n",
       "Arumugam Duraisamy        99114625     NaN  360.00  120.0  160.00\n",
       "Narender Loganathan         442223  153.00  178.00  124.0  153.00\n",
       "Gangamahesh Parasa        99088901     NaN  357.00  118.9  144.50\n",
       "Arun Govindasamy            436843  114.75  101.75  140.5  136.25\n",
       "Prakash S                   442998  131.50  198.50  133.5  134.00\n",
       "Bhupal Reddy              99101998     NaN  352.00   80.0  128.00\n",
       "Manish Kumar Rajak        99117567     NaN  340.00  127.5  119.00\n",
       "Mahesh Yanamala             447490  170.00  177.00  170.0  110.50\n",
       "Sathish Kumar Namani      99101630     NaN  195.00   66.0   82.00\n",
       "Suneetha Narni              439840  161.50  -13.00   98.0   78.00\n",
       "Sneha Sharma              99104131     NaN  328.00    NaN     NaN\n",
       "Raju Sripathi             99116465     NaN  160.00    NaN     NaN\n",
       "Rajesh                    99116466     NaN     NaN    NaN     NaN"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>99007714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>99018294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>99112394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>99119422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>99111227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aditya Gaurav</td>\n",
       "      <td>99121343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arun Kumar Molugu</td>\n",
       "      <td>99084053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sivakumar Veluru</td>\n",
       "      <td>99099398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.52</td>\n",
       "      <td>127.5</td>\n",
       "      <td>195.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sathish Kumar K</td>\n",
       "      <td>99101824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pavan Kumar HS</td>\n",
       "      <td>99116600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Venu Lekkalapudi</td>\n",
       "      <td>99104115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Basappa Allannavar</td>\n",
       "      <td>99101891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Krishnaprasad Damodharan</td>\n",
       "      <td>439853</td>\n",
       "      <td>153.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.0</td>\n",
       "      <td>163.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Arumugam Duraisamy</td>\n",
       "      <td>99114625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Narender Loganathan</td>\n",
       "      <td>442223</td>\n",
       "      <td>153.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gangamahesh Parasa</td>\n",
       "      <td>99088901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.00</td>\n",
       "      <td>118.9</td>\n",
       "      <td>144.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Arun Govindasamy</td>\n",
       "      <td>436843</td>\n",
       "      <td>114.75</td>\n",
       "      <td>101.75</td>\n",
       "      <td>140.5</td>\n",
       "      <td>136.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Prakash S</td>\n",
       "      <td>442998</td>\n",
       "      <td>131.50</td>\n",
       "      <td>198.50</td>\n",
       "      <td>133.5</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bhupal Reddy</td>\n",
       "      <td>99101998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>128.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Manish Kumar Rajak</td>\n",
       "      <td>99117567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>119.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mahesh Yanamala</td>\n",
       "      <td>447490</td>\n",
       "      <td>170.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>99101630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>439840</td>\n",
       "      <td>161.50</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>99104131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>99116465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Rajesh</td>\n",
       "      <td>99116466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name     EMPID    Col1    Col2   Col3    Col4\n",
       "0                 Amit Purty  99007714     NaN  301.75   85.0  233.50\n",
       "1              Lavanya Chapa  99018294     NaN  263.50  127.5  212.50\n",
       "2                Sunil Undar  99097931     NaN  382.50  127.5  212.50\n",
       "3               Yogesh Uppal  99112394     NaN  306.00  127.5  212.50\n",
       "4                 SURAJ JAIN  99119422     NaN  408.00  119.0  212.50\n",
       "5      Jyothish Kumar Bellam  99111227     NaN  374.00  119.0  204.00\n",
       "6              Aditya Gaurav  99121343     NaN  374.00  119.0  204.00\n",
       "7          Arun Kumar Molugu  99084053     NaN  336.00  112.0  200.00\n",
       "8           Sivakumar Veluru  99099398     NaN  348.52  127.5  195.50\n",
       "9            Sathish Kumar K  99101824     NaN  304.00   88.0  192.00\n",
       "10            Pavan Kumar HS  99116600     NaN  336.00  128.0  192.00\n",
       "11          Venu Lekkalapudi  99104115     NaN  299.00  120.0  177.00\n",
       "12        Basappa Allannavar  99101891     NaN  320.00  128.0  166.00\n",
       "13  Krishnaprasad Damodharan    439853  153.00  147.50  143.0  163.00\n",
       "14        Arumugam Duraisamy  99114625     NaN  360.00  120.0  160.00\n",
       "15       Narender Loganathan    442223  153.00  178.00  124.0  153.00\n",
       "16        Gangamahesh Parasa  99088901     NaN  357.00  118.9  144.50\n",
       "17          Arun Govindasamy    436843  114.75  101.75  140.5  136.25\n",
       "18                 Prakash S    442998  131.50  198.50  133.5  134.00\n",
       "19              Bhupal Reddy  99101998     NaN  352.00   80.0  128.00\n",
       "20        Manish Kumar Rajak  99117567     NaN  340.00  127.5  119.00\n",
       "21           Mahesh Yanamala    447490  170.00  177.00  170.0  110.50\n",
       "22      Sathish Kumar Namani  99101630     NaN  195.00   66.0   82.00\n",
       "23            Suneetha Narni    439840  161.50  -13.00   98.0   78.00\n",
       "24              Sneha Sharma  99104131     NaN  328.00    NaN     NaN\n",
       "25             Raju Sripathi  99116465     NaN  160.00    NaN     NaN\n",
       "26                    Rajesh  99116466     NaN     NaN    NaN     NaN"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ONly now changes will be confirmed\n",
    "new_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMPID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99007714</th>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99018294</th>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99097931</th>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99112394</th>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99119422</th>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99111227</th>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99121343</th>\n",
       "      <td>Aditya Gaurav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99084053</th>\n",
       "      <td>Arun Kumar Molugu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99099398</th>\n",
       "      <td>Sivakumar Veluru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.52</td>\n",
       "      <td>127.5</td>\n",
       "      <td>195.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99101824</th>\n",
       "      <td>Sathish Kumar K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99116600</th>\n",
       "      <td>Pavan Kumar HS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99104115</th>\n",
       "      <td>Venu Lekkalapudi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99101891</th>\n",
       "      <td>Basappa Allannavar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439853</th>\n",
       "      <td>Krishnaprasad Damodharan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.0</td>\n",
       "      <td>163.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99114625</th>\n",
       "      <td>Arumugam Duraisamy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442223</th>\n",
       "      <td>Narender Loganathan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99088901</th>\n",
       "      <td>Gangamahesh Parasa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.00</td>\n",
       "      <td>118.9</td>\n",
       "      <td>144.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436843</th>\n",
       "      <td>Arun Govindasamy</td>\n",
       "      <td>114.75</td>\n",
       "      <td>101.75</td>\n",
       "      <td>140.5</td>\n",
       "      <td>136.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442998</th>\n",
       "      <td>Prakash S</td>\n",
       "      <td>131.50</td>\n",
       "      <td>198.50</td>\n",
       "      <td>133.5</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99101998</th>\n",
       "      <td>Bhupal Reddy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>128.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99117567</th>\n",
       "      <td>Manish Kumar Rajak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>119.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447490</th>\n",
       "      <td>Mahesh Yanamala</td>\n",
       "      <td>170.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99101630</th>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439840</th>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>161.50</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99104131</th>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99116465</th>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99116466</th>\n",
       "      <td>Rajesh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Col1    Col2   Col3    Col4\n",
       "EMPID                                                            \n",
       "99007714                Amit Purty     NaN  301.75   85.0  233.50\n",
       "99018294             Lavanya Chapa     NaN  263.50  127.5  212.50\n",
       "99097931               Sunil Undar     NaN  382.50  127.5  212.50\n",
       "99112394              Yogesh Uppal     NaN  306.00  127.5  212.50\n",
       "99119422                SURAJ JAIN     NaN  408.00  119.0  212.50\n",
       "99111227     Jyothish Kumar Bellam     NaN  374.00  119.0  204.00\n",
       "99121343             Aditya Gaurav     NaN  374.00  119.0  204.00\n",
       "99084053         Arun Kumar Molugu     NaN  336.00  112.0  200.00\n",
       "99099398          Sivakumar Veluru     NaN  348.52  127.5  195.50\n",
       "99101824           Sathish Kumar K     NaN  304.00   88.0  192.00\n",
       "99116600            Pavan Kumar HS     NaN  336.00  128.0  192.00\n",
       "99104115          Venu Lekkalapudi     NaN  299.00  120.0  177.00\n",
       "99101891        Basappa Allannavar     NaN  320.00  128.0  166.00\n",
       "439853    Krishnaprasad Damodharan  153.00  147.50  143.0  163.00\n",
       "99114625        Arumugam Duraisamy     NaN  360.00  120.0  160.00\n",
       "442223         Narender Loganathan  153.00  178.00  124.0  153.00\n",
       "99088901        Gangamahesh Parasa     NaN  357.00  118.9  144.50\n",
       "436843            Arun Govindasamy  114.75  101.75  140.5  136.25\n",
       "442998                   Prakash S  131.50  198.50  133.5  134.00\n",
       "99101998              Bhupal Reddy     NaN  352.00   80.0  128.00\n",
       "99117567        Manish Kumar Rajak     NaN  340.00  127.5  119.00\n",
       "447490             Mahesh Yanamala  170.00  177.00  170.0  110.50\n",
       "99101630      Sathish Kumar Namani     NaN  195.00   66.0   82.00\n",
       "439840              Suneetha Narni  161.50  -13.00   98.0   78.00\n",
       "99104131              Sneha Sharma     NaN  328.00    NaN     NaN\n",
       "99116465             Raju Sripathi     NaN  160.00    NaN     NaN\n",
       "99116466                    Rajesh     NaN     NaN    NaN     NaN"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.set_index(\"EMPID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Col1', 'Col2', 'Col3', 'Col4'], dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.set_index(\"EMPID\").columns\n",
    "#if you see EMPID is no longer in the column list. This is what we mean by removing it from the columns or data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EMPID', 'Col1', 'Col2', 'Col3', 'Col4'], dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.set_index(\"Name\").columns\n",
    "#new_excel.loc['99007714']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>99007714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>99018294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>99112394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>99119422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name     EMPID  Col1    Col2   Col3   Col4\n",
       "0     Amit Purty  99007714   NaN  301.75   85.0  233.5\n",
       "1  Lavanya Chapa  99018294   NaN  263.50  127.5  212.5\n",
       "2    Sunil Undar  99097931   NaN  382.50  127.5  212.5\n",
       "3   Yogesh Uppal  99112394   NaN  306.00  127.5  212.5\n",
       "4     SURAJ JAIN  99119422   NaN  408.00  119.0  212.5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_excel.loc['Amit Purty']\n",
    "new_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>99007714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>99018294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>99112394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>99119422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           Name     EMPID  Col1    Col2   Col3   Col4\n",
       "0      0     Amit Purty  99007714   NaN  301.75   85.0  233.5\n",
       "1      1  Lavanya Chapa  99018294   NaN  263.50  127.5  212.5\n",
       "2      2    Sunil Undar  99097931   NaN  382.50  127.5  212.5\n",
       "3      3   Yogesh Uppal  99112394   NaN  306.00  127.5  212.5\n",
       "4      4     SURAJ JAIN  99119422   NaN  408.00  119.0  212.5"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>99007714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>99018294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>99112394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>99119422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>99111227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                   Name     EMPID  Col1    Col2   Col3   Col4\n",
       "0      0             Amit Purty  99007714   NaN  301.75   85.0  233.5\n",
       "1      1          Lavanya Chapa  99018294   NaN  263.50  127.5  212.5\n",
       "2      2            Sunil Undar  99097931   NaN  382.50  127.5  212.5\n",
       "3      3           Yogesh Uppal  99112394   NaN  306.00  127.5  212.5\n",
       "4      4             SURAJ JAIN  99119422   NaN  408.00  119.0  212.5\n",
       "5      5  Jyothish Kumar Bellam  99111227   NaN  374.00  119.0  204.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.loc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jyothish Kumar Bellam'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loc[rowlabel:columnlabel]\n",
    "new_excel.loc[5,\"Name\"]\n",
    "#Intersection of row 5 and column 'Name' which is Jyothish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Col1\n",
       "2            Sunil Undar   NaN\n",
       "3           Yogesh Uppal   NaN\n",
       "4             SURAJ JAIN   NaN\n",
       "5  Jyothish Kumar Bellam   NaN"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.loc[2:5,[\"Name\",\"Col1\"]]\n",
    "#Whenever passing more than one column put it in []- pass as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.5</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>99112394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.0</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>99119422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>99111227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name     EMPID  Col1   Col2   Col3\n",
       "2            Sunil Undar  99097931   NaN  382.5  127.5\n",
       "3           Yogesh Uppal  99112394   NaN  306.0  127.5\n",
       "4             SURAJ JAIN  99119422   NaN  408.0  119.0\n",
       "5  Jyothish Kumar Bellam  99111227   NaN  374.0  119.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.loc[2:5,\"Name\":\"Col3\"].head()\n",
    "# This is a label based search and which is why all values are included unlike index based search. We don't need list here as\n",
    "#it is a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name   Col3\n",
       "2            Sunil Undar  127.5\n",
       "3           Yogesh Uppal  127.5\n",
       "5  Jyothish Kumar Bellam  119.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.loc[[2,3,5],[\"Name\",\"Col3\"]].head()\n",
    "#if we want 2,3 and 5 separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Col1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name  Col1\n",
       "0     Amit Purty   NaN\n",
       "1  Lavanya Chapa   NaN\n",
       "2    Sunil Undar   NaN\n",
       "3   Yogesh Uppal   NaN\n",
       "4     SURAJ JAIN   NaN"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.loc[:,[\"Name\",\"Col1\"]].head()\n",
    "#Get me all the rows for Name and Col1. This is another way to get all the rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>99007714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>99018294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>99112394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>99119422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           Name     EMPID  Col1    Col2   Col3   Col4\n",
       "0      0     Amit Purty  99007714   NaN  301.75   85.0  233.5\n",
       "1      1  Lavanya Chapa  99018294   NaN  263.50  127.5  212.5\n",
       "2      2    Sunil Undar  99097931   NaN  382.50  127.5  212.5\n",
       "3      3   Yogesh Uppal  99112394   NaN  306.00  127.5  212.5\n",
       "4      4     SURAJ JAIN  99119422   NaN  408.00  119.0  212.5"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.loc[:,:].head()\n",
    "#to get all columns and all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>99018294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.5</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>99097931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.5</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           Name     EMPID  Col1   Col2   Col3   Col4\n",
       "1      1  Lavanya Chapa  99018294   NaN  263.5  127.5  212.5\n",
       "2      2    Sunil Undar  99097931   NaN  382.5  127.5  212.5"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To access based on position (not based on label)\n",
    "new_excel.iloc[1:3,:].head()\n",
    "#since this is position based, it will exclude 3 index, print 0,1 and 2 and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index\n",
       "0      0\n",
       "1      1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.iloc[0:2,0:1]\n",
    "#Gives for the first two rows the first column (0 and 1) and one column (index 0). In iloc, we have to get integer position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1 Read the csv file\n",
    "bike_sharing_orig = pd.read_csv(\"C:/Users/tin2419/Desktop/DSFiles/bike_sharing_python.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/20/2011 0:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/20/2011 1:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/20/2011 2:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/20/2011 3:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/20/2011 4:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
       "0  1/20/2011 0:00     1.0      0.0         1.0      1.0  10.66  11.365   \n",
       "1  1/20/2011 1:00     1.0      0.0         1.0      1.0  10.66  13.635   \n",
       "2  1/20/2011 2:00     1.0      0.0         1.0      1.0  10.66  13.635   \n",
       "3  1/20/2011 3:00     1.0      0.0         1.0      1.0  10.66  12.880   \n",
       "4  1/20/2011 4:00     1.0      0.0         1.0      1.0  10.66  12.880   \n",
       "\n",
       "   humidity  windspeed  \n",
       "0      56.0    26.0027  \n",
       "1      56.0     0.0000  \n",
       "2      56.0     0.0000  \n",
       "3      56.0    11.0014  \n",
       "4      56.0    11.0014  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2 Print the data types\n",
    "bike_sharing_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_sharing = bike_sharing_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime      1\n",
       "season        4\n",
       "holiday       2\n",
       "workingday    3\n",
       "weather       3\n",
       "temp          3\n",
       "atemp         3\n",
       "humidity      2\n",
       "windspeed     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3 Check for null values\n",
    "bike_sharing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/20/2011 0:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/20/2011 1:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/20/2011 2:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/20/2011 3:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/20/2011 4:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/20/2011 5:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/20/2011 6:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/20/2011 7:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/20/2011 8:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/20/2011 9:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/20/2011 10:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1/20/2011 11:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>13.635</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/20/2011 12:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>16.665</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1/20/2011 13:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>14.395</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1/20/2011 14:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1/20/2011 15:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>15.910</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1/20/2011 16:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1/20/2011 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.910</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1/20/2011 18:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1/20/2011 19:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1/20/2011 20:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.120</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1/20/2011 21:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1/20/2011 23:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>10.605</td>\n",
       "      <td>65.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1/21/2011 0:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1/21/2011 1:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1/21/2011 2:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>12.120</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1/21/2011 3:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1/21/2011 4:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>12.880</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1/21/2011 5:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>9.850</td>\n",
       "      <td>60.0</td>\n",
       "      <td>27.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1/21/2011 6:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>12/30/2012 18:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>10.605</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>12/30/2012 19:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.94</td>\n",
       "      <td>18.180</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>12/30/2012 20:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>9.850</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>12/30/2012 21:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>10.605</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>12/30/2012 22:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>9.850</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>12/30/2012 23:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>9.850</td>\n",
       "      <td>51.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>12/31/2012 0:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.090</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>12/31/2012 1:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.090</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>12/31/2012 2:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>8.335</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>12/31/2012 3:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>9.090</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>12/31/2012 4:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>8.335</td>\n",
       "      <td>69.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>12/31/2012 5:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>7.575</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>12/31/2012 6:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>8.335</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>12/31/2012 7:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>9.090</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>12/31/2012 8:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.575</td>\n",
       "      <td>69.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>12/31/2012 9:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>10.605</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>12/31/2012 10:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>10.605</td>\n",
       "      <td>69.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "      <td>12/31/2012 11:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>11.365</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6481</th>\n",
       "      <td>12/31/2012 12:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>12/31/2012 13:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>44.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>12/31/2012 14:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>13.635</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>12/31/2012 15:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>14.395</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>12/31/2012 16:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>48.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>12/31/2012 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>14.395</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>12/31/2012 18:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>12/31/2012 19:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>12/31/2012 20:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>12/31/2012 21:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>12/31/2012 22:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>12/31/2012 23:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
       "0       1/20/2011 0:00     1.0      0.0         1.0      1.0  10.66  11.365   \n",
       "1       1/20/2011 1:00     1.0      0.0         1.0      1.0  10.66  13.635   \n",
       "2       1/20/2011 2:00     1.0      0.0         1.0      1.0  10.66  13.635   \n",
       "3       1/20/2011 3:00     1.0      0.0         1.0      1.0  10.66  12.880   \n",
       "4       1/20/2011 4:00     1.0      0.0         1.0      1.0  10.66  12.880   \n",
       "5       1/20/2011 5:00     1.0      0.0         1.0      1.0   9.84  11.365   \n",
       "6       1/20/2011 6:00     1.0      0.0         1.0      1.0   9.02  10.605   \n",
       "7       1/20/2011 7:00     1.0      0.0         1.0      1.0   9.02  10.605   \n",
       "8       1/20/2011 8:00     1.0      0.0         1.0      1.0   9.02  10.605   \n",
       "9       1/20/2011 9:00     1.0      0.0         1.0      2.0   9.84  11.365   \n",
       "10     1/20/2011 10:00     1.0      0.0         1.0      1.0  10.66  11.365   \n",
       "11     1/20/2011 11:00     1.0      0.0         1.0      2.0  11.48  13.635   \n",
       "12     1/20/2011 12:00     1.0      0.0         1.0      2.0  12.30  16.665   \n",
       "13     1/20/2011 13:00     1.0      0.0         1.0      2.0  11.48  14.395   \n",
       "14     1/20/2011 14:00     1.0      0.0         1.0      2.0  12.30  15.150   \n",
       "15     1/20/2011 15:00     1.0      0.0         1.0      2.0  13.12  15.910   \n",
       "16     1/20/2011 16:00     1.0      0.0         1.0      2.0  12.30  15.150   \n",
       "17     1/20/2011 17:00     1.0      0.0         1.0      2.0  12.30  15.910   \n",
       "18     1/20/2011 18:00     1.0      0.0         1.0      2.0  10.66  12.880   \n",
       "19     1/20/2011 19:00     1.0      0.0         1.0      1.0  10.66  11.365   \n",
       "20     1/20/2011 20:00     1.0      0.0         1.0      2.0  10.66  12.120   \n",
       "21     1/20/2011 21:00     1.0      0.0         1.0      2.0   9.84  11.365   \n",
       "23     1/20/2011 23:00     1.0      0.0         1.0      2.0   9.84  10.605   \n",
       "24      1/21/2011 0:00     1.0      0.0         1.0      2.0   9.84  11.365   \n",
       "25      1/21/2011 1:00     1.0      0.0         1.0      2.0   9.84  11.365   \n",
       "26      1/21/2011 2:00     1.0      0.0         1.0      3.0   9.84  12.120   \n",
       "27      1/21/2011 3:00     1.0      0.0         1.0      3.0   9.02  10.605   \n",
       "28      1/21/2011 4:00     1.0      0.0         1.0      2.0   9.02  12.880   \n",
       "29      1/21/2011 5:00     1.0      0.0         1.0      1.0   9.84   9.850   \n",
       "30      1/21/2011 6:00     1.0      0.0         1.0      1.0   9.02  10.605   \n",
       "...                ...     ...      ...         ...      ...    ...     ...   \n",
       "6463  12/30/2012 18:00     1.0      0.0         0.0      2.0   9.84  10.605   \n",
       "6464  12/30/2012 19:00     1.0      0.0         0.0      1.0  13.94  18.180   \n",
       "6465  12/30/2012 20:00     1.0      0.0         0.0      1.0   9.02   9.850   \n",
       "6466  12/30/2012 21:00     1.0      0.0         0.0      1.0   8.20  10.605   \n",
       "6467  12/30/2012 22:00     1.0      0.0         0.0      1.0   8.20   9.850   \n",
       "6468  12/30/2012 23:00     1.0      0.0         0.0      1.0   8.20   9.850   \n",
       "6469   12/31/2012 0:00     1.0      0.0         1.0      1.0   7.38   9.090   \n",
       "6470   12/31/2012 1:00     1.0      0.0         1.0      1.0   7.38   9.090   \n",
       "6471   12/31/2012 2:00     1.0      0.0         1.0      1.0   6.56   8.335   \n",
       "6472   12/31/2012 3:00     1.0      0.0         1.0      1.0   6.56   9.090   \n",
       "6473   12/31/2012 4:00     1.0      0.0         1.0      1.0   5.74   8.335   \n",
       "6474   12/31/2012 5:00     1.0      0.0         1.0      1.0   6.56   7.575   \n",
       "6475   12/31/2012 6:00     1.0      0.0         1.0      1.0   6.56   8.335   \n",
       "6476   12/31/2012 7:00     1.0      0.0         1.0      1.0   6.56   9.090   \n",
       "6477   12/31/2012 8:00     1.0      0.0         1.0      1.0   5.74   7.575   \n",
       "6478   12/31/2012 9:00     1.0      0.0         1.0      2.0   7.38  10.605   \n",
       "6479  12/31/2012 10:00     1.0      0.0         1.0      2.0   8.20  10.605   \n",
       "6480  12/31/2012 11:00     1.0      0.0         1.0      2.0   9.02  11.365   \n",
       "6481  12/31/2012 12:00     1.0      0.0         1.0      2.0   9.84  11.365   \n",
       "6482  12/31/2012 13:00     1.0      0.0         1.0      2.0  10.66  12.880   \n",
       "6483  12/31/2012 14:00     1.0      0.0         1.0      2.0  11.48  13.635   \n",
       "6484  12/31/2012 15:00     1.0      0.0         1.0      2.0  11.48  14.395   \n",
       "6485  12/31/2012 16:00     1.0      0.0         1.0      2.0  10.66  12.880   \n",
       "6486  12/31/2012 17:00     1.0      0.0         1.0      2.0  10.66  14.395   \n",
       "6487  12/31/2012 18:00     1.0      0.0         1.0      2.0  10.66  13.635   \n",
       "6488  12/31/2012 19:00     1.0      0.0         1.0      2.0  10.66  12.880   \n",
       "6489  12/31/2012 20:00     1.0      0.0         1.0      2.0  10.66  12.880   \n",
       "6490  12/31/2012 21:00     1.0      0.0         1.0      1.0  10.66  12.880   \n",
       "6491  12/31/2012 22:00     1.0      0.0         1.0      1.0  10.66  13.635   \n",
       "6492  12/31/2012 23:00     1.0      0.0         1.0      1.0  10.66  13.635   \n",
       "\n",
       "      humidity  windspeed  \n",
       "0         56.0    26.0027  \n",
       "1         56.0     0.0000  \n",
       "2         56.0     0.0000  \n",
       "3         56.0    11.0014  \n",
       "4         56.0    11.0014  \n",
       "5         60.0    15.0013  \n",
       "6         60.0    15.0013  \n",
       "7         55.0    15.0013  \n",
       "8         55.0    19.0012  \n",
       "9         52.0    15.0013  \n",
       "10        48.0    19.9995  \n",
       "11        45.0    11.0014  \n",
       "12        42.0     0.0000  \n",
       "13        45.0     7.0015  \n",
       "14        45.0     8.9981  \n",
       "15        45.0    12.9980  \n",
       "16        49.0     8.9981  \n",
       "17        49.0     7.0015  \n",
       "18        56.0    12.9980  \n",
       "19        56.0    22.0028  \n",
       "20        60.0    19.0012  \n",
       "21        60.0    16.9979  \n",
       "23        65.0    22.0028  \n",
       "24        70.0    16.9979  \n",
       "25        70.0    16.9979  \n",
       "26        75.0    11.0014  \n",
       "27        80.0    19.9995  \n",
       "28        87.0     6.0032  \n",
       "29        60.0    27.9993  \n",
       "30        55.0    16.9979  \n",
       "...        ...        ...  \n",
       "6463      44.0    19.9995  \n",
       "6464      61.0     0.0000  \n",
       "6465      47.0    22.0028  \n",
       "6466      51.0    11.0014  \n",
       "6467      55.0    12.9980  \n",
       "6468      51.0    15.0013  \n",
       "6469      55.0    12.9980  \n",
       "6470      55.0    12.9980  \n",
       "6471      59.0    11.0014  \n",
       "6472      59.0     7.0015  \n",
       "6473      69.0     7.0015  \n",
       "6474      64.0    12.9980  \n",
       "6475      64.0    11.0014  \n",
       "6476      64.0     8.9981  \n",
       "6477      69.0     8.9981  \n",
       "6478      64.0     7.0015  \n",
       "6479      69.0     8.9981  \n",
       "6480      60.0    12.9980  \n",
       "6481      56.0    12.9980  \n",
       "6482      44.0    11.0014  \n",
       "6483      45.0    15.0013  \n",
       "6484      45.0     8.9981  \n",
       "6485      48.0    12.9980  \n",
       "6486      48.0     6.0032  \n",
       "6487      48.0     8.9981  \n",
       "6488      60.0    11.0014  \n",
       "6489      60.0    11.0014  \n",
       "6490      60.0    11.0014  \n",
       "6491      56.0     8.9981  \n",
       "6492      65.0     8.9981  \n",
       "\n",
       "[1459 rows x 9 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4 All the rows where season = 1and holiday = 0\n",
    "bike_sharing[(bike_sharing[\"season\"]==1)&(bike_sharing[\"holiday\"]==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>3/22/2011 13:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>3/22/2011 14:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>42.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>3/22/2011 15:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>3/22/2011 16:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>3/22/2011 17:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>4/20/2011 12:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.70</td>\n",
       "      <td>32.575</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>4/20/2011 13:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.70</td>\n",
       "      <td>32.575</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>4/20/2011 14:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>32.575</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>4/20/2011 15:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.16</td>\n",
       "      <td>33.335</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>4/20/2011 16:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.16</td>\n",
       "      <td>33.335</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>4/20/2011 17:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>32.575</td>\n",
       "      <td>37.0</td>\n",
       "      <td>27.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>4/20/2011 18:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>32.575</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>4/20/2011 19:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.70</td>\n",
       "      <td>31.820</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>4/20/2011 20:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>31.060</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>4/20/2011 21:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.06</td>\n",
       "      <td>31.060</td>\n",
       "      <td>36.0</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>4/20/2011 22:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.42</td>\n",
       "      <td>31.060</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>4/20/2011 23:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.60</td>\n",
       "      <td>31.060</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>4/21/2011 0:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.96</td>\n",
       "      <td>26.515</td>\n",
       "      <td>43.0</td>\n",
       "      <td>23.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>4/21/2011 1:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.32</td>\n",
       "      <td>25.000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>4/21/2011 2:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>42.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>4/21/2011 14:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>4/21/2011 15:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.32</td>\n",
       "      <td>25.000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>4/21/2011 16:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.32</td>\n",
       "      <td>25.000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>4/21/2011 17:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>4/21/2011 18:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>4/24/2011 14:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.70</td>\n",
       "      <td>32.575</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>4/24/2011 16:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>33.335</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>4/25/2011 14:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.52</td>\n",
       "      <td>33.335</td>\n",
       "      <td>54.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>4/25/2011 15:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>33.335</td>\n",
       "      <td>51.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>4/25/2011 16:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.70</td>\n",
       "      <td>32.575</td>\n",
       "      <td>54.0</td>\n",
       "      <td>23.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>10/22/2012 10:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>10/22/2012 11:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.96</td>\n",
       "      <td>26.515</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>10/22/2012 12:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.78</td>\n",
       "      <td>27.275</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>10/22/2012 13:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.42</td>\n",
       "      <td>31.060</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>10/22/2012 14:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.42</td>\n",
       "      <td>30.305</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>10/22/2012 15:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.24</td>\n",
       "      <td>31.060</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5756</th>\n",
       "      <td>10/22/2012 16:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.42</td>\n",
       "      <td>31.060</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>10/22/2012 17:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.42</td>\n",
       "      <td>31.060</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>10/22/2012 19:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.32</td>\n",
       "      <td>25.000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>10/23/2012 11:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.60</td>\n",
       "      <td>31.060</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5776</th>\n",
       "      <td>10/23/2012 12:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.42</td>\n",
       "      <td>31.060</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5777</th>\n",
       "      <td>10/23/2012 13:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.24</td>\n",
       "      <td>31.060</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>10/23/2012 14:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>31.820</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>10/23/2012 15:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>31.820</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>10/23/2012 16:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>31.820</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>10/23/2012 17:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>31.820</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5782</th>\n",
       "      <td>10/23/2012 18:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.42</td>\n",
       "      <td>31.060</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>10/24/2012 13:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.06</td>\n",
       "      <td>31.060</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>10/24/2012 14:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>32.575</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>10/24/2012 15:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.70</td>\n",
       "      <td>31.820</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>10/24/2012 16:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>32.575</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>10/24/2012 17:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.06</td>\n",
       "      <td>31.060</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>10/24/2012 18:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.06</td>\n",
       "      <td>31.060</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5807</th>\n",
       "      <td>10/24/2012 19:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.24</td>\n",
       "      <td>31.060</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>10/27/2012 12:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.60</td>\n",
       "      <td>31.060</td>\n",
       "      <td>53.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>10/27/2012 13:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.60</td>\n",
       "      <td>31.060</td>\n",
       "      <td>43.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>10/27/2012 14:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.60</td>\n",
       "      <td>31.060</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5893</th>\n",
       "      <td>10/28/2012 9:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>55.0</td>\n",
       "      <td>27.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>10/28/2012 11:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6030</th>\n",
       "      <td>11/23/2012 14:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.50</td>\n",
       "      <td>24.240</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1183 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
       "520    3/22/2011 13:00     2.0      0.0         1.0      1.0  20.50  24.240   \n",
       "521    3/22/2011 14:00     2.0      0.0         1.0      1.0  20.50  24.240   \n",
       "522    3/22/2011 15:00     2.0      0.0         1.0      1.0  20.50  24.240   \n",
       "523    3/22/2011 16:00     2.0      0.0         1.0      1.0  20.50  24.240   \n",
       "524    3/22/2011 17:00     2.0      0.0         1.0      1.0  20.50  24.240   \n",
       "756    4/20/2011 12:00     2.0      0.0         1.0      1.0  28.70  32.575   \n",
       "757    4/20/2011 13:00     2.0      0.0         1.0      1.0  28.70  32.575   \n",
       "758    4/20/2011 14:00     2.0      0.0         1.0      1.0  30.34  32.575   \n",
       "759    4/20/2011 15:00     2.0      0.0         1.0      2.0  31.16  33.335   \n",
       "760    4/20/2011 16:00     2.0      0.0         1.0      2.0  31.16  33.335   \n",
       "761    4/20/2011 17:00     2.0      0.0         1.0      2.0  30.34  32.575   \n",
       "762    4/20/2011 18:00     2.0      0.0         1.0      1.0  30.34  32.575   \n",
       "763    4/20/2011 19:00     2.0      0.0         1.0      1.0  28.70  31.820   \n",
       "764    4/20/2011 20:00     2.0      0.0         1.0      1.0  27.88  31.060   \n",
       "765    4/20/2011 21:00     2.0      0.0         1.0      1.0  27.06  31.060   \n",
       "766    4/20/2011 22:00     2.0      0.0         1.0      1.0  25.42  31.060   \n",
       "767    4/20/2011 23:00     2.0      0.0         1.0      1.0  24.60  31.060   \n",
       "768     4/21/2011 0:00     2.0      0.0         1.0      1.0  22.96  26.515   \n",
       "769     4/21/2011 1:00     2.0      0.0         1.0      1.0  21.32  25.000   \n",
       "770     4/21/2011 2:00     2.0      0.0         1.0      1.0  20.50  24.240   \n",
       "782    4/21/2011 14:00     2.0      0.0         1.0      1.0  20.50  24.240   \n",
       "783    4/21/2011 15:00     2.0      0.0         1.0      1.0  21.32  25.000   \n",
       "784    4/21/2011 16:00     2.0      0.0         1.0      1.0  21.32  25.000   \n",
       "785    4/21/2011 17:00     2.0      0.0         1.0      1.0  20.50  24.240   \n",
       "786    4/21/2011 18:00     2.0      0.0         1.0      1.0  20.50  24.240   \n",
       "854    4/24/2011 14:00     2.0      0.0         0.0      1.0  28.70  32.575   \n",
       "856    4/24/2011 16:00     2.0      0.0         0.0      1.0  30.34  33.335   \n",
       "878    4/25/2011 14:00     2.0      0.0         1.0      1.0  29.52  33.335   \n",
       "879    4/25/2011 15:00     2.0      0.0         1.0      1.0  30.34  33.335   \n",
       "880    4/25/2011 16:00     2.0      0.0         1.0      1.0  28.70  32.575   \n",
       "...                ...     ...      ...         ...      ...    ...     ...   \n",
       "5750  10/22/2012 10:00     4.0      0.0         1.0      1.0  20.50  24.240   \n",
       "5751  10/22/2012 11:00     4.0      0.0         1.0      1.0  22.96  26.515   \n",
       "5752  10/22/2012 12:00     4.0      0.0         1.0      1.0  23.78  27.275   \n",
       "5753  10/22/2012 13:00     4.0      0.0         1.0      1.0  25.42  31.060   \n",
       "5754  10/22/2012 14:00     4.0      0.0         1.0      1.0  25.42  30.305   \n",
       "5755  10/22/2012 15:00     4.0      0.0         1.0      1.0  26.24  31.060   \n",
       "5756  10/22/2012 16:00     4.0      0.0         1.0      1.0  25.42  31.060   \n",
       "5757  10/22/2012 17:00     4.0      0.0         1.0      1.0  25.42  31.060   \n",
       "5759  10/22/2012 19:00     4.0      0.0         1.0      1.0  21.32  25.000   \n",
       "5775  10/23/2012 11:00     4.0      0.0         1.0      1.0  24.60  31.060   \n",
       "5776  10/23/2012 12:00     4.0      0.0         1.0      2.0  25.42  31.060   \n",
       "5777  10/23/2012 13:00     4.0      0.0         1.0      2.0  26.24  31.060   \n",
       "5778  10/23/2012 14:00     4.0      0.0         1.0      1.0  27.88  31.820   \n",
       "5779  10/23/2012 15:00     4.0      0.0         1.0      1.0  27.88  31.820   \n",
       "5780  10/23/2012 16:00     4.0      0.0         1.0      1.0  27.88  31.820   \n",
       "5781  10/23/2012 17:00     4.0      0.0         1.0      1.0  27.88  31.820   \n",
       "5782  10/23/2012 18:00     4.0      0.0         1.0      1.0  25.42  31.060   \n",
       "5801  10/24/2012 13:00     4.0      0.0         1.0      1.0  27.06  31.060   \n",
       "5802  10/24/2012 14:00     4.0      0.0         1.0      1.0  30.34  32.575   \n",
       "5803  10/24/2012 15:00     4.0      0.0         1.0      1.0  28.70  31.820   \n",
       "5804  10/24/2012 16:00     4.0      0.0         1.0      1.0  30.34  32.575   \n",
       "5805  10/24/2012 17:00     4.0      0.0         1.0      1.0  27.06  31.060   \n",
       "5806  10/24/2012 18:00     4.0      0.0         1.0      1.0  27.06  31.060   \n",
       "5807  10/24/2012 19:00     4.0      0.0         1.0      2.0  26.24  31.060   \n",
       "5872  10/27/2012 12:00     4.0      0.0         0.0      1.0  24.60  31.060   \n",
       "5873  10/27/2012 13:00     4.0      0.0         0.0      1.0  24.60  31.060   \n",
       "5874  10/27/2012 14:00     4.0      0.0         0.0      1.0  24.60  31.060   \n",
       "5893   10/28/2012 9:00     4.0      0.0         0.0      2.0  20.50  24.240   \n",
       "5895  10/28/2012 11:00     4.0      0.0         0.0      2.0  20.50  24.240   \n",
       "6030  11/23/2012 14:00     4.0      0.0         1.0      1.0  20.50  24.240   \n",
       "\n",
       "      humidity  windspeed  \n",
       "520       45.0    15.0013  \n",
       "521       42.0    22.0028  \n",
       "522       42.0    15.0013  \n",
       "523       42.0     7.0015  \n",
       "524       42.0     7.0015  \n",
       "756       48.0    26.0027  \n",
       "757       48.0    26.0027  \n",
       "758       40.0    31.0009  \n",
       "759       35.0    23.9994  \n",
       "760       35.0    23.9994  \n",
       "761       37.0    27.9993  \n",
       "762       30.0    23.9994  \n",
       "763       32.0    16.9979  \n",
       "764       32.0     7.0015  \n",
       "765       36.0    19.0012  \n",
       "766       41.0    16.9979  \n",
       "767       40.0    22.0028  \n",
       "768       43.0    23.9994  \n",
       "769       45.0    15.0013  \n",
       "770       42.0    26.0027  \n",
       "782       34.0    26.0027  \n",
       "783       29.0    27.9993  \n",
       "784       27.0    23.9994  \n",
       "785       29.0    11.0014  \n",
       "786       25.0    19.0012  \n",
       "854       54.0    22.0028  \n",
       "856       48.0    26.0027  \n",
       "878       54.0    15.0013  \n",
       "879       51.0    15.0013  \n",
       "880       54.0    23.9994  \n",
       "...        ...        ...  \n",
       "5750      55.0     0.0000  \n",
       "5751      37.0    11.0014  \n",
       "5752      35.0     0.0000  \n",
       "5753      29.0    11.0014  \n",
       "5754      27.0    12.9980  \n",
       "5755      29.0    11.0014  \n",
       "5756      33.0    11.0014  \n",
       "5757      33.0     7.0015  \n",
       "5759      52.0     7.0015  \n",
       "5775      53.0     0.0000  \n",
       "5776      46.0     6.0032  \n",
       "5777      44.0     0.0000  \n",
       "5778      41.0    11.0014  \n",
       "5779      41.0    15.0013  \n",
       "5780      44.0     6.0032  \n",
       "5781      41.0     0.0000  \n",
       "5782      53.0     6.0032  \n",
       "5801      54.0     0.0000  \n",
       "5802      30.0    16.9979  \n",
       "5803      39.0     7.0015  \n",
       "5804      33.0     8.9981  \n",
       "5805      47.0     0.0000  \n",
       "5806      44.0     0.0000  \n",
       "5807      53.0     6.0032  \n",
       "5872      53.0    16.9979  \n",
       "5873      43.0    16.9979  \n",
       "5874      46.0    16.9979  \n",
       "5893      55.0    27.9993  \n",
       "5895      51.0    26.0027  \n",
       "6030      36.0    16.9979  \n",
       "\n",
       "[1183 rows x 9 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5 All the rows where temp>20  and humidity < 56\n",
    "bike_sharing[(bike_sharing[\"temp\"]>20)&(bike_sharing[\"humidity\"]<56)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2/25/2011 14:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.96</td>\n",
       "      <td>26.515</td>\n",
       "      <td>56.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2/25/2011 15:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.86</td>\n",
       "      <td>22.725</td>\n",
       "      <td>41.0</td>\n",
       "      <td>54.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2/25/2011 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>13.635</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2/25/2011 20:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.880</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2/28/2011 19:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.04</td>\n",
       "      <td>21.970</td>\n",
       "      <td>88.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2/28/2011 20:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.04</td>\n",
       "      <td>21.970</td>\n",
       "      <td>88.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>3/23/2011 20:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.76</td>\n",
       "      <td>15.150</td>\n",
       "      <td>87.0</td>\n",
       "      <td>43.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>8/27/2011 17:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.24</td>\n",
       "      <td>28.790</td>\n",
       "      <td>89.0</td>\n",
       "      <td>55.9986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>8/28/2011 10:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.70</td>\n",
       "      <td>32.575</td>\n",
       "      <td>61.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>2/24/2012 21:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.22</td>\n",
       "      <td>21.210</td>\n",
       "      <td>35.0</td>\n",
       "      <td>54.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>2/24/2012 23:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.58</td>\n",
       "      <td>19.695</td>\n",
       "      <td>37.0</td>\n",
       "      <td>46.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>2/25/2012 11:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.880</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>2/25/2012 12:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>13.635</td>\n",
       "      <td>29.0</td>\n",
       "      <td>43.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3905</th>\n",
       "      <td>3/26/2012 13:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>23.485</td>\n",
       "      <td>29.0</td>\n",
       "      <td>46.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>3/26/2012 15:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>23.485</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>3/26/2012 16:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>23.485</td>\n",
       "      <td>25.0</td>\n",
       "      <td>43.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>7/26/2012 21:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.80</td>\n",
       "      <td>37.120</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>7/26/2012 22:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.80</td>\n",
       "      <td>37.120</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>11/24/2012 2:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>13.635</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>11/24/2012 12:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.880</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>12/22/2012 8:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.605</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>12/22/2012 12:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.880</td>\n",
       "      <td>36.0</td>\n",
       "      <td>43.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>12/30/2012 13:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>12.880</td>\n",
       "      <td>36.0</td>\n",
       "      <td>43.9989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
       "381    2/25/2011 14:00     1.0      0.0         1.0      3.0  22.96  26.515   \n",
       "382    2/25/2011 15:00     1.0      0.0         1.0      1.0  18.86  22.725   \n",
       "384    2/25/2011 17:00     1.0      0.0         1.0      1.0  13.12  13.635   \n",
       "387    2/25/2011 20:00     1.0      0.0         1.0      1.0  12.30  12.880   \n",
       "455    2/28/2011 19:00     1.0      0.0         1.0      3.0  18.04  21.970   \n",
       "456    2/28/2011 20:00     1.0      0.0         1.0      3.0  18.04  21.970   \n",
       "550    3/23/2011 20:00     2.0      0.0         1.0      3.0  14.76  15.150   \n",
       "2033   8/27/2011 17:00     3.0      0.0         0.0      3.0  26.24  28.790   \n",
       "2037   8/28/2011 10:00     3.0      0.0         0.0      1.0  28.70  32.575   \n",
       "3626   2/24/2012 21:00     1.0      0.0         1.0      1.0  17.22  21.210   \n",
       "3628   2/24/2012 23:00     1.0      0.0         1.0      1.0  15.58  19.695   \n",
       "3640   2/25/2012 11:00     1.0      0.0         0.0      1.0  12.30  12.880   \n",
       "3641   2/25/2012 12:00     1.0      0.0         0.0      1.0  13.12  13.635   \n",
       "3905   3/26/2012 13:00     2.0      0.0         1.0      1.0  19.68  23.485   \n",
       "3907   3/26/2012 15:00     2.0      0.0         1.0      1.0  19.68  23.485   \n",
       "3908   3/26/2012 16:00     2.0      0.0         1.0      1.0  19.68  23.485   \n",
       "5017   7/26/2012 21:00     3.0      0.0         1.0      1.0  32.80  37.120   \n",
       "5018   7/26/2012 22:00     3.0      0.0         1.0      1.0  32.80  37.120   \n",
       "6042   11/24/2012 2:00     4.0      0.0         0.0      1.0  13.12  13.635   \n",
       "6052  11/24/2012 12:00     4.0      0.0         0.0      2.0  12.30  12.880   \n",
       "6263   12/22/2012 8:00     1.0      0.0         0.0      1.0  10.66  10.605   \n",
       "6267  12/22/2012 12:00     1.0      0.0         0.0      1.0  12.30  12.880   \n",
       "6458  12/30/2012 13:00     1.0      0.0         0.0      1.0  12.30  12.880   \n",
       "\n",
       "      humidity  windspeed  \n",
       "381       56.0    40.9973  \n",
       "382       41.0    54.0020  \n",
       "384       49.0    50.0021  \n",
       "387       49.0    40.9973  \n",
       "455       88.0    40.9973  \n",
       "456       88.0    40.9973  \n",
       "550       87.0    43.0006  \n",
       "2033      89.0    55.9986  \n",
       "2037      61.0    40.9973  \n",
       "3626      35.0    54.0020  \n",
       "3628      37.0    46.0022  \n",
       "3640      39.0    40.9973  \n",
       "3641      29.0    43.9989  \n",
       "3905      29.0    46.0022  \n",
       "3907      29.0    40.9973  \n",
       "3908      25.0    43.0006  \n",
       "5017      49.0    40.9973  \n",
       "5018      49.0    40.9973  \n",
       "6042      39.0    40.9973  \n",
       "6052      36.0    40.9973  \n",
       "6263      44.0    40.9973  \n",
       "6267      36.0    43.9989  \n",
       "6458      36.0    43.9989  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6 Find the number of rows where windspeed > 40\n",
    "bike_sharing[bike_sharing[\"windspeed\"]>40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6481</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6493 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      weather   temp\n",
       "0         1.0  10.66\n",
       "1         1.0  10.66\n",
       "2         1.0  10.66\n",
       "3         1.0  10.66\n",
       "4         1.0  10.66\n",
       "5         1.0   9.84\n",
       "6         1.0   9.02\n",
       "7         1.0   9.02\n",
       "8         1.0   9.02\n",
       "9         2.0   9.84\n",
       "10        1.0  10.66\n",
       "11        2.0  11.48\n",
       "12        2.0  12.30\n",
       "13        2.0  11.48\n",
       "14        2.0  12.30\n",
       "15        2.0  13.12\n",
       "16        2.0  12.30\n",
       "17        2.0  12.30\n",
       "18        2.0  10.66\n",
       "19        1.0  10.66\n",
       "20        2.0  10.66\n",
       "21        2.0   9.84\n",
       "22        2.0   9.84\n",
       "23        2.0   9.84\n",
       "24        2.0   9.84\n",
       "25        2.0   9.84\n",
       "26        3.0   9.84\n",
       "27        3.0   9.02\n",
       "28        2.0   9.02\n",
       "29        1.0   9.84\n",
       "...       ...    ...\n",
       "6463      2.0   9.84\n",
       "6464      1.0  13.94\n",
       "6465      1.0   9.02\n",
       "6466      1.0   8.20\n",
       "6467      1.0   8.20\n",
       "6468      1.0   8.20\n",
       "6469      1.0   7.38\n",
       "6470      1.0   7.38\n",
       "6471      1.0   6.56\n",
       "6472      1.0   6.56\n",
       "6473      1.0   5.74\n",
       "6474      1.0   6.56\n",
       "6475      1.0   6.56\n",
       "6476      1.0   6.56\n",
       "6477      1.0   5.74\n",
       "6478      2.0   7.38\n",
       "6479      2.0   8.20\n",
       "6480      2.0   9.02\n",
       "6481      2.0   9.84\n",
       "6482      2.0  10.66\n",
       "6483      2.0  11.48\n",
       "6484      2.0  11.48\n",
       "6485      2.0  10.66\n",
       "6486      2.0  10.66\n",
       "6487      2.0  10.66\n",
       "6488      2.0  10.66\n",
       "6489      2.0  10.66\n",
       "6490      1.0  10.66\n",
       "6491      1.0  10.66\n",
       "6492      1.0  10.66\n",
       "\n",
       "[6493 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7 Get weather and temp using loc\n",
    "bike_sharing.loc[:,[\"weather\",\"temp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    holiday  humidity\n",
       "2       0.0      56.0\n",
       "3       0.0      56.0\n",
       "10      0.0      48.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8. Get 2,3,10 index and holiday and humidity column\n",
    "bike_sharing.loc[[2,3,10],[\"holiday\",\"humidity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.48</td>\n",
       "      <td>13.635</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.30</td>\n",
       "      <td>16.665</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.48</td>\n",
       "      <td>14.395</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     temp   atemp  humidity\n",
       "10  10.66  11.365      48.0\n",
       "11  11.48  13.635      45.0\n",
       "12  12.30  16.665      42.0\n",
       "13  11.48  14.395      45.0\n",
       "14  12.30  15.150      45.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9. Get rows 10 to 15 position and column with 5 to 7 position\n",
    "bike_sharing.iloc[10:16,5:8].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6481</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6493 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[6493 rows x 0 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q10. Drop the rows which contain at least one null value\n",
    "bike_sharing[bike_sharing.isnull().any(axis=1)]\n",
    "#bike_sharing.dropna(how=\"any\",axis=1) - not sure what this does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   datetime  season  holiday  workingday  weather  temp  atemp  humidity  \\\n",
       "64      NaN     NaN      NaN         NaN      NaN   NaN    NaN       NaN   \n",
       "\n",
       "    windspeed  \n",
       "64        NaN  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q11. Drop the rows which contains all the null values\n",
    "bike_sharing[bike_sharing.isnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bike_sharing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-29d7e0a2ca5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbike_sharing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bike_sharing' is not defined"
     ]
    }
   ],
   "source": [
    "bike_sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_sharing_drop = bike_sharing.dropna(how=\"all\",axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_sharing_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6492, 9)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6492, 9)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-54ab0cae8af5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbike_sharing_drop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "bike_sharing_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_sharing_drop  = bike_sharing.dropna(how=\"all\",axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6492, 9)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6493, 9)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_sharing_orig = bike_sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   datetime  season  holiday  workingday  weather  temp  atemp  humidity  \\\n",
       "64      NaN     NaN      NaN         NaN      NaN   NaN    NaN       NaN   \n",
       "\n",
       "    windspeed  \n",
       "64        NaN  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing[bike_sharing.isnull().all(axis=1)]\n",
    "#show the row where all the values in the columns(axis=1)is null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11th Aug - Class 4 - How to drop a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>April Month</th>\n",
       "      <th>May Month</th>\n",
       "      <th>June Month</th>\n",
       "      <th>July Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99007714</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99018294</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99112394</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99119422</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMPID           Name  April Month  May Month  June Month  July Month\n",
       "0  99007714     Amit Purty          NaN     301.75        85.0       233.5\n",
       "1  99018294  Lavanya Chapa          NaN     263.50       127.5       212.5\n",
       "2  99097931    Sunil Undar          NaN     382.50       127.5       212.5\n",
       "3  99112394   Yogesh Uppal          NaN     306.00       127.5       212.5\n",
       "4  99119422     SURAJ JAIN          NaN     408.00       119.0       212.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bike_sharing.shape\n",
    "import pandas as pd\n",
    "new_excel = pd.read_excel(\"C:/Users/tin2419/Desktop/DSFiles/timereport.xlsx\",skiprows=3)\n",
    "new_excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Usually we don't get the full path name, we normally get the relative path name to read a file. We will come to this\n",
    "#to skiprows=4,nrows=10000 (will fetch only 10000 records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/20/2011 0:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/20/2011 1:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/20/2011 2:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/20/2011 3:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/20/2011 4:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/20/2011 5:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/20/2011 6:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/20/2011 7:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/20/2011 8:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/20/2011 9:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/20/2011 10:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1/20/2011 11:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>13.635</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/20/2011 12:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>16.665</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1/20/2011 13:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>14.395</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1/20/2011 14:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1/20/2011 15:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>15.910</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1/20/2011 16:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1/20/2011 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.910</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1/20/2011 18:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1/20/2011 19:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1/20/2011 20:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.120</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1/20/2011 21:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1/20/2011 22:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>10.605</td>\n",
       "      <td>65.0</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1/20/2011 23:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>10.605</td>\n",
       "      <td>65.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1/21/2011 0:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1/21/2011 1:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1/21/2011 2:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>12.120</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1/21/2011 3:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1/21/2011 4:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>12.880</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1/21/2011 5:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>9.850</td>\n",
       "      <td>60.0</td>\n",
       "      <td>27.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>12/30/2012 18:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>10.605</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>12/30/2012 19:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.94</td>\n",
       "      <td>18.180</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>12/30/2012 20:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>9.850</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>12/30/2012 21:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>10.605</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>12/30/2012 22:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>9.850</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>12/30/2012 23:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>9.850</td>\n",
       "      <td>51.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>12/31/2012 0:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.090</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>12/31/2012 1:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.090</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>12/31/2012 2:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>8.335</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>12/31/2012 3:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>9.090</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>12/31/2012 4:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>8.335</td>\n",
       "      <td>69.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>12/31/2012 5:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>7.575</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>12/31/2012 6:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>8.335</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>12/31/2012 7:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>9.090</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>12/31/2012 8:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>7.575</td>\n",
       "      <td>69.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>12/31/2012 9:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>10.605</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>12/31/2012 10:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>10.605</td>\n",
       "      <td>69.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "      <td>12/31/2012 11:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>11.365</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6481</th>\n",
       "      <td>12/31/2012 12:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>12/31/2012 13:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>44.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>12/31/2012 14:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>13.635</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>12/31/2012 15:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>14.395</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>12/31/2012 16:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>48.0</td>\n",
       "      <td>12.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>12/31/2012 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>14.395</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>12/31/2012 18:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>12/31/2012 19:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>12/31/2012 20:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>12/31/2012 21:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>12/31/2012 22:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>12/31/2012 23:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8.9981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6493 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  workingday  weather   temp   atemp  humidity  \\\n",
       "0       1/20/2011 0:00     1.0         1.0      1.0  10.66  11.365      56.0   \n",
       "1       1/20/2011 1:00     1.0         1.0      1.0  10.66  13.635      56.0   \n",
       "2       1/20/2011 2:00     1.0         1.0      1.0  10.66  13.635      56.0   \n",
       "3       1/20/2011 3:00     1.0         1.0      1.0  10.66  12.880      56.0   \n",
       "4       1/20/2011 4:00     1.0         1.0      1.0  10.66  12.880      56.0   \n",
       "5       1/20/2011 5:00     1.0         1.0      1.0   9.84  11.365      60.0   \n",
       "6       1/20/2011 6:00     1.0         1.0      1.0   9.02  10.605      60.0   \n",
       "7       1/20/2011 7:00     1.0         1.0      1.0   9.02  10.605      55.0   \n",
       "8       1/20/2011 8:00     1.0         1.0      1.0   9.02  10.605      55.0   \n",
       "9       1/20/2011 9:00     1.0         1.0      2.0   9.84  11.365      52.0   \n",
       "10     1/20/2011 10:00     1.0         1.0      1.0  10.66  11.365      48.0   \n",
       "11     1/20/2011 11:00     1.0         1.0      2.0  11.48  13.635      45.0   \n",
       "12     1/20/2011 12:00     1.0         1.0      2.0  12.30  16.665      42.0   \n",
       "13     1/20/2011 13:00     1.0         1.0      2.0  11.48  14.395      45.0   \n",
       "14     1/20/2011 14:00     1.0         1.0      2.0  12.30  15.150      45.0   \n",
       "15     1/20/2011 15:00     1.0         1.0      2.0  13.12  15.910      45.0   \n",
       "16     1/20/2011 16:00     1.0         1.0      2.0  12.30  15.150      49.0   \n",
       "17     1/20/2011 17:00     1.0         1.0      2.0  12.30  15.910      49.0   \n",
       "18     1/20/2011 18:00     1.0         1.0      2.0  10.66  12.880      56.0   \n",
       "19     1/20/2011 19:00     1.0         1.0      1.0  10.66  11.365      56.0   \n",
       "20     1/20/2011 20:00     1.0         1.0      2.0  10.66  12.120      60.0   \n",
       "21     1/20/2011 21:00     1.0         1.0      2.0   9.84  11.365      60.0   \n",
       "22     1/20/2011 22:00     NaN         1.0      2.0   9.84  10.605      65.0   \n",
       "23     1/20/2011 23:00     1.0         1.0      2.0   9.84  10.605      65.0   \n",
       "24      1/21/2011 0:00     1.0         1.0      2.0   9.84  11.365      70.0   \n",
       "25      1/21/2011 1:00     1.0         1.0      2.0   9.84  11.365      70.0   \n",
       "26      1/21/2011 2:00     1.0         1.0      3.0   9.84  12.120      75.0   \n",
       "27      1/21/2011 3:00     1.0         1.0      3.0   9.02  10.605      80.0   \n",
       "28      1/21/2011 4:00     1.0         1.0      2.0   9.02  12.880      87.0   \n",
       "29      1/21/2011 5:00     1.0         1.0      1.0   9.84   9.850      60.0   \n",
       "...                ...     ...         ...      ...    ...     ...       ...   \n",
       "6463  12/30/2012 18:00     1.0         0.0      2.0   9.84  10.605      44.0   \n",
       "6464  12/30/2012 19:00     1.0         0.0      1.0  13.94  18.180      61.0   \n",
       "6465  12/30/2012 20:00     1.0         0.0      1.0   9.02   9.850      47.0   \n",
       "6466  12/30/2012 21:00     1.0         0.0      1.0   8.20  10.605      51.0   \n",
       "6467  12/30/2012 22:00     1.0         0.0      1.0   8.20   9.850      55.0   \n",
       "6468  12/30/2012 23:00     1.0         0.0      1.0   8.20   9.850      51.0   \n",
       "6469   12/31/2012 0:00     1.0         1.0      1.0   7.38   9.090      55.0   \n",
       "6470   12/31/2012 1:00     1.0         1.0      1.0   7.38   9.090      55.0   \n",
       "6471   12/31/2012 2:00     1.0         1.0      1.0   6.56   8.335      59.0   \n",
       "6472   12/31/2012 3:00     1.0         1.0      1.0   6.56   9.090      59.0   \n",
       "6473   12/31/2012 4:00     1.0         1.0      1.0   5.74   8.335      69.0   \n",
       "6474   12/31/2012 5:00     1.0         1.0      1.0   6.56   7.575      64.0   \n",
       "6475   12/31/2012 6:00     1.0         1.0      1.0   6.56   8.335      64.0   \n",
       "6476   12/31/2012 7:00     1.0         1.0      1.0   6.56   9.090      64.0   \n",
       "6477   12/31/2012 8:00     1.0         1.0      1.0   5.74   7.575      69.0   \n",
       "6478   12/31/2012 9:00     1.0         1.0      2.0   7.38  10.605      64.0   \n",
       "6479  12/31/2012 10:00     1.0         1.0      2.0   8.20  10.605      69.0   \n",
       "6480  12/31/2012 11:00     1.0         1.0      2.0   9.02  11.365      60.0   \n",
       "6481  12/31/2012 12:00     1.0         1.0      2.0   9.84  11.365      56.0   \n",
       "6482  12/31/2012 13:00     1.0         1.0      2.0  10.66  12.880      44.0   \n",
       "6483  12/31/2012 14:00     1.0         1.0      2.0  11.48  13.635      45.0   \n",
       "6484  12/31/2012 15:00     1.0         1.0      2.0  11.48  14.395      45.0   \n",
       "6485  12/31/2012 16:00     1.0         1.0      2.0  10.66  12.880      48.0   \n",
       "6486  12/31/2012 17:00     1.0         1.0      2.0  10.66  14.395      48.0   \n",
       "6487  12/31/2012 18:00     1.0         1.0      2.0  10.66  13.635      48.0   \n",
       "6488  12/31/2012 19:00     1.0         1.0      2.0  10.66  12.880      60.0   \n",
       "6489  12/31/2012 20:00     1.0         1.0      2.0  10.66  12.880      60.0   \n",
       "6490  12/31/2012 21:00     1.0         1.0      1.0  10.66  12.880      60.0   \n",
       "6491  12/31/2012 22:00     1.0         1.0      1.0  10.66  13.635      56.0   \n",
       "6492  12/31/2012 23:00     1.0         1.0      1.0  10.66  13.635      65.0   \n",
       "\n",
       "      windspeed  \n",
       "0       26.0027  \n",
       "1        0.0000  \n",
       "2        0.0000  \n",
       "3       11.0014  \n",
       "4       11.0014  \n",
       "5       15.0013  \n",
       "6       15.0013  \n",
       "7       15.0013  \n",
       "8       19.0012  \n",
       "9       15.0013  \n",
       "10      19.9995  \n",
       "11      11.0014  \n",
       "12       0.0000  \n",
       "13       7.0015  \n",
       "14       8.9981  \n",
       "15      12.9980  \n",
       "16       8.9981  \n",
       "17       7.0015  \n",
       "18      12.9980  \n",
       "19      22.0028  \n",
       "20      19.0012  \n",
       "21      16.9979  \n",
       "22      19.0012  \n",
       "23      22.0028  \n",
       "24      16.9979  \n",
       "25      16.9979  \n",
       "26      11.0014  \n",
       "27      19.9995  \n",
       "28       6.0032  \n",
       "29      27.9993  \n",
       "...         ...  \n",
       "6463    19.9995  \n",
       "6464     0.0000  \n",
       "6465    22.0028  \n",
       "6466    11.0014  \n",
       "6467    12.9980  \n",
       "6468    15.0013  \n",
       "6469    12.9980  \n",
       "6470    12.9980  \n",
       "6471    11.0014  \n",
       "6472     7.0015  \n",
       "6473     7.0015  \n",
       "6474    12.9980  \n",
       "6475    11.0014  \n",
       "6476     8.9981  \n",
       "6477     8.9981  \n",
       "6478     7.0015  \n",
       "6479     8.9981  \n",
       "6480    12.9980  \n",
       "6481    12.9980  \n",
       "6482    11.0014  \n",
       "6483    15.0013  \n",
       "6484     8.9981  \n",
       "6485    12.9980  \n",
       "6486     6.0032  \n",
       "6487     8.9981  \n",
       "6488    11.0014  \n",
       "6489    11.0014  \n",
       "6490    11.0014  \n",
       "6491     8.9981  \n",
       "6492     8.9981  \n",
       "\n",
       "[6493 rows x 8 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to drop a column\n",
    "bike_sharing.drop([\"holiday\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>April Month</th>\n",
       "      <th>May Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99007714</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99018294</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99112394</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99119422</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMPID           Name  April Month  May Month\n",
       "0  99007714     Amit Purty          NaN     301.75\n",
       "1  99018294  Lavanya Chapa          NaN     263.50\n",
       "2  99097931    Sunil Undar          NaN     382.50\n",
       "3  99112394   Yogesh Uppal          NaN     306.00\n",
       "4  99119422     SURAJ JAIN          NaN     408.00"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To drop more than one column, we have to pass it as a list\n",
    "new_excel.drop([\"June Month\",\"July Month\"],axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>April Month</th>\n",
       "      <th>May Month</th>\n",
       "      <th>June Month</th>\n",
       "      <th>July Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99018294</td>\n",
       "      <td>Lavanya Chapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99112394</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99119422</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99111227</td>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99121343</td>\n",
       "      <td>Aditya Gaurav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99084053</td>\n",
       "      <td>Arun Kumar Molugu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99099398</td>\n",
       "      <td>Sivakumar Veluru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.52</td>\n",
       "      <td>127.5</td>\n",
       "      <td>195.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99101824</td>\n",
       "      <td>Sathish Kumar K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99116600</td>\n",
       "      <td>Pavan Kumar HS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>99104115</td>\n",
       "      <td>Venu Lekkalapudi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>99101891</td>\n",
       "      <td>Basappa Allannavar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>439853</td>\n",
       "      <td>Krishnaprasad Damodharan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.0</td>\n",
       "      <td>163.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99114625</td>\n",
       "      <td>Arumugam Duraisamy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>442223</td>\n",
       "      <td>Narender Loganathan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>99088901</td>\n",
       "      <td>Gangamahesh Parasa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.00</td>\n",
       "      <td>118.9</td>\n",
       "      <td>144.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>436843</td>\n",
       "      <td>Arun Govindasamy</td>\n",
       "      <td>114.75</td>\n",
       "      <td>101.75</td>\n",
       "      <td>140.5</td>\n",
       "      <td>136.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>442998</td>\n",
       "      <td>Prakash S</td>\n",
       "      <td>131.50</td>\n",
       "      <td>198.50</td>\n",
       "      <td>133.5</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>99101998</td>\n",
       "      <td>Bhupal Reddy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>128.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>99117567</td>\n",
       "      <td>Manish Kumar Rajak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>119.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>447490</td>\n",
       "      <td>Mahesh Yanamala</td>\n",
       "      <td>170.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99101630</td>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>439840</td>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>161.50</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>99104131</td>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>99116465</td>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMPID                      Name  April Month  May Month  June Month  \\\n",
       "1   99018294             Lavanya Chapa          NaN     263.50       127.5   \n",
       "2   99097931               Sunil Undar          NaN     382.50       127.5   \n",
       "3   99112394              Yogesh Uppal          NaN     306.00       127.5   \n",
       "4   99119422                SURAJ JAIN          NaN     408.00       119.0   \n",
       "5   99111227     Jyothish Kumar Bellam          NaN     374.00       119.0   \n",
       "6   99121343             Aditya Gaurav          NaN     374.00       119.0   \n",
       "7   99084053         Arun Kumar Molugu          NaN     336.00       112.0   \n",
       "8   99099398          Sivakumar Veluru          NaN     348.52       127.5   \n",
       "9   99101824           Sathish Kumar K          NaN     304.00        88.0   \n",
       "10  99116600            Pavan Kumar HS          NaN     336.00       128.0   \n",
       "11  99104115          Venu Lekkalapudi          NaN     299.00       120.0   \n",
       "12  99101891        Basappa Allannavar          NaN     320.00       128.0   \n",
       "13    439853  Krishnaprasad Damodharan       153.00     147.50       143.0   \n",
       "14  99114625        Arumugam Duraisamy          NaN     360.00       120.0   \n",
       "15    442223       Narender Loganathan       153.00     178.00       124.0   \n",
       "16  99088901        Gangamahesh Parasa          NaN     357.00       118.9   \n",
       "17    436843          Arun Govindasamy       114.75     101.75       140.5   \n",
       "18    442998                 Prakash S       131.50     198.50       133.5   \n",
       "19  99101998              Bhupal Reddy          NaN     352.00        80.0   \n",
       "20  99117567        Manish Kumar Rajak          NaN     340.00       127.5   \n",
       "21    447490           Mahesh Yanamala       170.00     177.00       170.0   \n",
       "22  99101630      Sathish Kumar Namani          NaN     195.00        66.0   \n",
       "23    439840            Suneetha Narni       161.50     -13.00        98.0   \n",
       "24  99104131              Sneha Sharma          NaN     328.00         NaN   \n",
       "25  99116465             Raju Sripathi          NaN     160.00         NaN   \n",
       "\n",
       "    July Month  \n",
       "1       212.50  \n",
       "2       212.50  \n",
       "3       212.50  \n",
       "4       212.50  \n",
       "5       204.00  \n",
       "6       204.00  \n",
       "7       200.00  \n",
       "8       195.50  \n",
       "9       192.00  \n",
       "10      192.00  \n",
       "11      177.00  \n",
       "12      166.00  \n",
       "13      163.00  \n",
       "14      160.00  \n",
       "15      153.00  \n",
       "16      144.50  \n",
       "17      136.25  \n",
       "18      134.00  \n",
       "19      128.00  \n",
       "20      119.00  \n",
       "21      110.50  \n",
       "22       82.00  \n",
       "23       78.00  \n",
       "24         NaN  \n",
       "25         NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To drop rows where some condition is met. For that we need to get an index matching that criteria\n",
    "#I want to drop all the rows where temp is 9.01\n",
    "#bike_sharing[bike_sharing[\"temp\"]==9.02].index - gives us the index numbers\n",
    "#bike_sharing.drop(bike_sharing[bike_sharing[\"temp\"]==9.02].index,axis=0)\n",
    "new_excel.drop(new_excel[new_excel[\"May Month\"]==301.75].index,axis=0)\n",
    "#We can avoid this if we put another column as the index as we don't have to use the above procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>Name</th>\n",
       "      <th>April Month</th>\n",
       "      <th>May Month</th>\n",
       "      <th>June Month</th>\n",
       "      <th>July Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99007714</td>\n",
       "      <td>Amit Purty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>233.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99097931</td>\n",
       "      <td>Sunil Undar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.50</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99112394</td>\n",
       "      <td>Yogesh Uppal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99119422</td>\n",
       "      <td>SURAJ JAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99111227</td>\n",
       "      <td>Jyothish Kumar Bellam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99121343</td>\n",
       "      <td>Aditya Gaurav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99084053</td>\n",
       "      <td>Arun Kumar Molugu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>112.0</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99099398</td>\n",
       "      <td>Sivakumar Veluru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.52</td>\n",
       "      <td>127.5</td>\n",
       "      <td>195.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99101824</td>\n",
       "      <td>Sathish Kumar K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99116600</td>\n",
       "      <td>Pavan Kumar HS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>99104115</td>\n",
       "      <td>Venu Lekkalapudi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>99101891</td>\n",
       "      <td>Basappa Allannavar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>439853</td>\n",
       "      <td>Krishnaprasad Damodharan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>147.50</td>\n",
       "      <td>143.0</td>\n",
       "      <td>163.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99114625</td>\n",
       "      <td>Arumugam Duraisamy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>442223</td>\n",
       "      <td>Narender Loganathan</td>\n",
       "      <td>153.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>99088901</td>\n",
       "      <td>Gangamahesh Parasa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.00</td>\n",
       "      <td>118.9</td>\n",
       "      <td>144.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>436843</td>\n",
       "      <td>Arun Govindasamy</td>\n",
       "      <td>114.75</td>\n",
       "      <td>101.75</td>\n",
       "      <td>140.5</td>\n",
       "      <td>136.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>442998</td>\n",
       "      <td>Prakash S</td>\n",
       "      <td>131.50</td>\n",
       "      <td>198.50</td>\n",
       "      <td>133.5</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>99101998</td>\n",
       "      <td>Bhupal Reddy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>128.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>99117567</td>\n",
       "      <td>Manish Kumar Rajak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.00</td>\n",
       "      <td>127.5</td>\n",
       "      <td>119.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>447490</td>\n",
       "      <td>Mahesh Yanamala</td>\n",
       "      <td>170.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>110.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>99101630</td>\n",
       "      <td>Sathish Kumar Namani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>439840</td>\n",
       "      <td>Suneetha Narni</td>\n",
       "      <td>161.50</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>99104131</td>\n",
       "      <td>Sneha Sharma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>99116465</td>\n",
       "      <td>Raju Sripathi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EMPID                      Name  April Month  May Month  June Month  \\\n",
       "0   99007714                Amit Purty          NaN     301.75        85.0   \n",
       "2   99097931               Sunil Undar          NaN     382.50       127.5   \n",
       "3   99112394              Yogesh Uppal          NaN     306.00       127.5   \n",
       "4   99119422                SURAJ JAIN          NaN     408.00       119.0   \n",
       "5   99111227     Jyothish Kumar Bellam          NaN     374.00       119.0   \n",
       "6   99121343             Aditya Gaurav          NaN     374.00       119.0   \n",
       "7   99084053         Arun Kumar Molugu          NaN     336.00       112.0   \n",
       "8   99099398          Sivakumar Veluru          NaN     348.52       127.5   \n",
       "9   99101824           Sathish Kumar K          NaN     304.00        88.0   \n",
       "10  99116600            Pavan Kumar HS          NaN     336.00       128.0   \n",
       "11  99104115          Venu Lekkalapudi          NaN     299.00       120.0   \n",
       "12  99101891        Basappa Allannavar          NaN     320.00       128.0   \n",
       "13    439853  Krishnaprasad Damodharan       153.00     147.50       143.0   \n",
       "14  99114625        Arumugam Duraisamy          NaN     360.00       120.0   \n",
       "15    442223       Narender Loganathan       153.00     178.00       124.0   \n",
       "16  99088901        Gangamahesh Parasa          NaN     357.00       118.9   \n",
       "17    436843          Arun Govindasamy       114.75     101.75       140.5   \n",
       "18    442998                 Prakash S       131.50     198.50       133.5   \n",
       "19  99101998              Bhupal Reddy          NaN     352.00        80.0   \n",
       "20  99117567        Manish Kumar Rajak          NaN     340.00       127.5   \n",
       "21    447490           Mahesh Yanamala       170.00     177.00       170.0   \n",
       "22  99101630      Sathish Kumar Namani          NaN     195.00        66.0   \n",
       "23    439840            Suneetha Narni       161.50     -13.00        98.0   \n",
       "24  99104131              Sneha Sharma          NaN     328.00         NaN   \n",
       "25  99116465             Raju Sripathi          NaN     160.00         NaN   \n",
       "\n",
       "    July Month  \n",
       "0       233.50  \n",
       "2       212.50  \n",
       "3       212.50  \n",
       "4       212.50  \n",
       "5       204.00  \n",
       "6       204.00  \n",
       "7       200.00  \n",
       "8       195.50  \n",
       "9       192.00  \n",
       "10      192.00  \n",
       "11      177.00  \n",
       "12      166.00  \n",
       "13      163.00  \n",
       "14      160.00  \n",
       "15      153.00  \n",
       "16      144.50  \n",
       "17      136.25  \n",
       "18      134.00  \n",
       "19      128.00  \n",
       "20      119.00  \n",
       "21      110.50  \n",
       "22       82.00  \n",
       "23       78.00  \n",
       "24         NaN  \n",
       "25         NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.drop(new_excel[(new_excel[\"May Month\"]==263.5)&(new_excel[\"June Month\"]==127.5)].index,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6493, 9)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6427, 9)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DROP THE DATA WHERE TEMP IS MORE THAN 20 AND THE SEASON IS 1\n",
    "bike_sharing.drop(bike_sharing[(bike_sharing[\"temp\"]>20)&(bike_sharing[\"season\"]==1)].index,axis=0).shape\n",
    "# if we are dropping by rows we need an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Like SQL, we have join in Pandas also. pd.merge() is used to join two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "empdata = pd.read_excel(\"C:/Users/tin2419/Desktop/DSFiles/empdata.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "deptdata= pd.read_excel(\"C:/Users/tin2419/Desktop/DSFiles/dept.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>did</th>\n",
       "      <th>dname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rajesh</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Roshan</td>\n",
       "      <td>20.0</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name   did dname\n",
       "0   1  Rajesh  10.0    IT\n",
       "1   2  Roshan  20.0   FIN"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(empdata,deptdata,on=\"did\",how=\"inner\")\n",
    "#This is an inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>did</th>\n",
       "      <th>dname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rajesh</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Roshan</td>\n",
       "      <td>20.0</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Prasad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name   did dname\n",
       "0   1  Rajesh  10.0    IT\n",
       "1   2  Roshan  20.0   FIN\n",
       "2   3  Prasad   NaN   NaN"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I want all the details irrespective of any joins - this gives inner plus the other data in the table - in this case we also got\n",
    "#Prasad\n",
    "pd.merge(empdata,deptdata,on=\"did\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#import OS will be able to find what type of files are there - whether it is .csv or .excel etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>did</th>\n",
       "      <th>dname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Rajesh</td>\n",
       "      <td>10.0</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Roshan</td>\n",
       "      <td>20.0</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>MARKETING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    name   did      dname\n",
       "0  1.0  Rajesh  10.0         IT\n",
       "1  2.0  Roshan  20.0        FIN\n",
       "2  NaN     NaN  30.0      SALES\n",
       "3  NaN     NaN  40.0  MARKETING"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are few depts that are not present in the employee table\n",
    "pd.merge(empdata,deptdata,on=\"did\",how=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ASSIGNMENT - CREATE AN EMPLOYEE TABLE AND LOCATION\n",
    "#EMP: EMPID, NAME, SALARY, LID\n",
    "#LOCATION: LID,CITY\n",
    "#TO GIVE EMPLOYEES ALOONG WITH CITY DETAILS WHERE SALARY IS GREATER THAN 40,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPDB = pd.DataFrame({\"EMPID\":[1,2,3,4],\"NAME\":[\"PC\",\"RANJ\",\"REJO\",\"SUNI\"],\"SALARY\":[500,300,200,100],\"LID\":[20,30,40,50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCDB = pd.DataFrame({\"LID\":[20,30,40,50,60,70],\"CITY\":[\"Chennai\",\"Bangalore\",\"Calicut\",\"Ooty\",\"Cochin\",\"Calcutta\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWTABLE = pd.merge(EMPDB,LOCDB,on=\"LID\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>LID</th>\n",
       "      <th>CITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PC</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>RANJ</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>REJO</td>\n",
       "      <td>200</td>\n",
       "      <td>40</td>\n",
       "      <td>Calicut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SUNI</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>Ooty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMPID  NAME  SALARY  LID       CITY\n",
       "0      1    PC     500   20    Chennai\n",
       "1      2  RANJ     300   30  Bangalore\n",
       "2      3  REJO     200   40    Calicut\n",
       "3      4  SUNI     100   50       Ooty"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWTABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER = NEWTABLE[NEWTABLE[\"SALARY\"]>200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>LID</th>\n",
       "      <th>CITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PC</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>RANJ</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>Bangalore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMPID  NAME  SALARY  LID       CITY\n",
       "0      1    PC     500   20    Chennai\n",
       "1      2  RANJ     300   30  Bangalore"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In realtime we may be joining with multiple columns not just with one column. Also, we might need to change the columns\n",
    "#df.columns = [<pass the column names] - this is done to rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EMPID', 'NAME', 'SALARY', 'LID', 'CITY'], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANSWER.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER.columns = [\"EID\",\"NAM\",\"SAL\",\"LID\",\"CTY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EID</th>\n",
       "      <th>NAM</th>\n",
       "      <th>SAL</th>\n",
       "      <th>LID</th>\n",
       "      <th>CTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PC</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>RANJ</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>Bangalore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EID   NAM  SAL  LID        CTY\n",
       "0    1    PC  500   20    Chennai\n",
       "1    2  RANJ  300   30  Bangalore"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANSWER\n",
    "#this has changed the columns and we don't need inplace = True here. That is only applicable in dropna. So be careful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To join more than two columns, pass it as a list [,,,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To merget two tables - completely\n",
    "bike_sharing1 = bike_sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12986, 9)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([bike_sharing,bike_sharing1], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pd.DataFrame({\"ID\":[1,2,3,4],\"NAME\":[\"PC\",\"DS\",\"RW\",\"TR\"],\"SALARY\":[20,30,40,50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "second = pd.DataFrame({\"SID\":[1,2,3,4],\"NAM\":[\"PC\",\"DS\",\"RW\",\"TR\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tin2419\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAM</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>SID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DS</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RW</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TR</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  NAM NAME  SALARY  SID\n",
       "0  1.0  NaN   PC    20.0  NaN\n",
       "1  2.0  NaN   DS    30.0  NaN\n",
       "2  3.0  NaN   RW    40.0  NaN\n",
       "3  4.0  NaN   TR    50.0  NaN\n",
       "0  NaN   PC  NaN     NaN  1.0\n",
       "1  NaN   DS  NaN     NaN  2.0\n",
       "2  NaN   RW  NaN     NaN  3.0\n",
       "3  NaN   TR  NaN     NaN  4.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([first,second],axis=0)\n",
    "#this will blindly concat even if it does not find the same column names. if it did not find the corresponding column names,\n",
    "#it will add these new column names on top and add null as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>SID</th>\n",
       "      <th>NAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PC</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DS</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>RW</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TR</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>TR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID NAME  SALARY  SID NAM\n",
       "0   1   PC      20    1  PC\n",
       "1   2   DS      30    2  DS\n",
       "2   3   RW      40    3  RW\n",
       "3   4   TR      50    4  TR"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To merge columns\n",
    "pd.concat([first,second],axis=1)\n",
    "#This will merge the two tables - no logic - it will have no nulls. If you have two tables sorted correctly then this will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#LETS LOOK AT GROUPBY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>25.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>36.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>40.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>31.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         temp\n",
       "season       \n",
       "1.0     25.42\n",
       "2.0     36.90\n",
       "3.0     40.18\n",
       "4.0     31.16"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The bike sharing people want to predict the number of bikes that people will take. I want season wise what is my maximum bike\n",
    "#sharing. Each season we want to find the season wise maximum temperature\n",
    "#bike_sharing = pd.read_csv(\"C:/Users/tin2419/Desktop/DSFiles/bike_sharing_python.csv\")\n",
    "bike_sharing.groupby(\"season\").agg({\"temp\":max})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">temp</th>\n",
       "      <th colspan=\"2\" halign=\"left\">humidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>25.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>100.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>36.90</td>\n",
       "      <td>6.56</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>40.18</td>\n",
       "      <td>18.04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>31.16</td>\n",
       "      <td>8.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         temp        humidity      \n",
       "          max    min      max   min\n",
       "season                             \n",
       "1.0     25.42   0.82    100.0  21.0\n",
       "2.0     36.90   6.56    100.0  16.0\n",
       "3.0     40.18  18.04    100.0  16.0\n",
       "4.0     31.16   8.20    100.0  27.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#power of groupby is that we can give many values at the same time\n",
    "bike_sharing.groupby(\"season\").agg({\"temp\":[max,min],\"humidity\":[max,min]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">temp</th>\n",
       "      <th colspan=\"2\" halign=\"left\">humidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>25.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>100.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>17.22</td>\n",
       "      <td>8.20</td>\n",
       "      <td>93.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>36.90</td>\n",
       "      <td>6.56</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>36.08</td>\n",
       "      <td>21.32</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>40.18</td>\n",
       "      <td>18.04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>31.16</td>\n",
       "      <td>8.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20.50</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 temp        humidity      \n",
       "                  max    min      max   min\n",
       "season holiday                             \n",
       "1.0    0.0      25.42   0.82    100.0  21.0\n",
       "       1.0      17.22   8.20     93.0  26.0\n",
       "2.0    0.0      36.90   6.56    100.0  16.0\n",
       "       1.0      36.08  21.32     94.0  37.0\n",
       "3.0    0.0      40.18  18.04    100.0  16.0\n",
       "4.0    0.0      31.16   8.20    100.0  27.0\n",
       "       1.0      20.50   9.02     80.0  29.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i want season wise holiday wise max and min temperature. here we have to pass two columns in groupby\n",
    "bike_sharing.groupby([\"season\",\"holiday\"]).agg({\"temp\":[\"max\",\"min\"],\"humidity\":[\"max\",\"min\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">windspeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>54.0020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>46.0022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>55.9986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>40.9973</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       windspeed     \n",
       "             max  min\n",
       "season               \n",
       "1.0      54.0020  0.0\n",
       "2.0      46.0022  0.0\n",
       "3.0      55.9986  0.0\n",
       "4.0      40.9973  0.0"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i want in a season, season-wise what is the maximum wind speed and minimum wind speed\n",
    "bike_sharing.groupby(\"season\").agg({\"windspeed\":[max,min]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrameGroupBy in module pandas.core.groupby.generic object:\n",
      "\n",
      "class DataFrameGroupBy(NDFrameGroupBy)\n",
      " |  DataFrameGroupBy(obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |  \n",
      " |  Class for grouping and aggregating relational data.\n",
      " |  \n",
      " |  See aggregate, transform, and apply functions on this object.\n",
      " |  \n",
      " |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = groupby(obj, ...)\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  obj : pandas object\n",
      " |  axis : int, default 0\n",
      " |  level : int, default None\n",
      " |      Level of MultiIndex\n",
      " |  groupings : list of Grouping objects\n",
      " |      Most users should ignore this\n",
      " |  exclusions : array-like, optional\n",
      " |      List of columns to exclude\n",
      " |  name : string\n",
      " |      Most users should ignore this\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  **Attributes**\n",
      " |  groups : dict\n",
      " |      {group name -> group labels}\n",
      " |  len(grouped) : int\n",
      " |      Number of groups\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  After grouping, see aggregate, apply, and transform functions. Here are\n",
      " |  some other brief notes about usage. When grouping by multiple groups, the\n",
      " |  result index will be a MultiIndex (hierarchical) by default.\n",
      " |  \n",
      " |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n",
      " |  you can write code like:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = obj.groupby(keys, axis=axis)\n",
      " |      for key, group in grouped:\n",
      " |          # do something with the data\n",
      " |  \n",
      " |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n",
      " |  grouped data. So if you group a DataFrame and wish to invoke the std()\n",
      " |  method on each group, you can simply do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).std()\n",
      " |  \n",
      " |  rather than\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).aggregate(np.std)\n",
      " |  \n",
      " |  You can pass arguments to these \"wrapped\" functions, too.\n",
      " |  \n",
      " |  See the online documentation for full exposition on these topics and much\n",
      " |  more\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrameGroupBy\n",
      " |      NDFrameGroupBy\n",
      " |      pandas.core.groupby.groupby.GroupBy\n",
      " |      pandas.core.groupby.groupby._GroupBy\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  agg = aggregate(self, arg, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, arg, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      \n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series or scalar\n",
      " |          if DataFrame.agg is called with a single function, returns a Series\n",
      " |          if DataFrame.agg is called with several functions, returns a DataFrame\n",
      " |          if Series.agg is called with single function, returns a scalar\n",
      " |          if Series.agg is called with several functions, returns a Series\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.groupby.apply\n",
      " |      pandas.DataFrame.groupby.transform\n",
      " |      pandas.DataFrame.aggregate\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n",
      " |      ...                    'B': [1, 2, 3, 4],\n",
      " |      ...                    'C': np.random.randn(4)})\n",
      " |      \n",
      " |      >>> df\n",
      " |         A  B         C\n",
      " |      0  1  1  0.362838\n",
      " |      1  1  2  0.227877\n",
      " |      2  2  3  1.267767\n",
      " |      3  2  4 -0.562860\n",
      " |      \n",
      " |      The aggregation is for each column.\n",
      " |      \n",
      " |      >>> df.groupby('A').agg('min')\n",
      " |         B         C\n",
      " |      A\n",
      " |      1  1  0.227877\n",
      " |      2  3 -0.562860\n",
      " |      \n",
      " |      Multiple aggregations\n",
      " |      \n",
      " |      >>> df.groupby('A').agg(['min', 'max'])\n",
      " |          B             C\n",
      " |        min max       min       max\n",
      " |      A\n",
      " |      1   1   2  0.227877  0.362838\n",
      " |      2   3   4 -0.562860  1.267767\n",
      " |      \n",
      " |      Select a column for aggregation\n",
      " |      \n",
      " |      >>> df.groupby('A').B.agg(['min', 'max'])\n",
      " |         min  max\n",
      " |      A\n",
      " |      1    1    2\n",
      " |      2    3    4\n",
      " |      \n",
      " |      Different aggregations per column\n",
      " |      \n",
      " |      >>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})\n",
      " |          B             C\n",
      " |        min max       sum\n",
      " |      A\n",
      " |      1   1   2  0.590716\n",
      " |      2   3   4  0.704907\n",
      " |  \n",
      " |  boxplot = boxplot_frame_groupby(grouped, subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, sharex=False, sharey=True, **kwds)\n",
      " |      Make box plots from DataFrameGroupBy data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      grouped : Grouped DataFrame\n",
      " |      subplots :\n",
      " |          * ``False`` - no subplots will be used\n",
      " |          * ``True`` - create a subplot for each group\n",
      " |      column : column name or list of names, or vector\n",
      " |          Can be any valid input to groupby\n",
      " |      fontsize : int or string\n",
      " |      rot : label rotation angle\n",
      " |      grid : Setting this to True will show the grid\n",
      " |      ax : Matplotlib axis object, default None\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |      layout : tuple (optional)\n",
      " |          (rows, columns) for the layout of the plot\n",
      " |      sharex : bool, default False\n",
      " |          Whether x-axes will be shared among subplots\n",
      " |      \n",
      " |          .. versionadded:: 0.23.1\n",
      " |      sharey : bool, default True\n",
      " |          Whether y-axes will be shared among subplots\n",
      " |      \n",
      " |          .. versionadded:: 0.23.1\n",
      " |      `**kwds` : Keyword Arguments\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          matplotlib's boxplot function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict of key/value = group key/DataFrame.boxplot return value\n",
      " |      or DataFrame.boxplot return value in case subplots=figures=False\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import itertools\n",
      " |      >>> tuples = [t for t in itertools.product(range(1000), range(4))]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n",
      " |      >>> data = np.random.randn(len(index),4)\n",
      " |      >>> df = pd.DataFrame(data, columns=list('ABCD'), index=index)\n",
      " |      >>>\n",
      " |      >>> grouped = df.groupby(level='lvl1')\n",
      " |      >>> boxplot_frame_groupby(grouped)\n",
      " |      >>>\n",
      " |      >>> grouped = df.unstack(level='lvl1').groupby(level=0, axis=1)\n",
      " |      >>> boxplot_frame_groupby(grouped, subplots=False)\n",
      " |  \n",
      " |  count(self)\n",
      " |      Compute count of group, excluding missing values\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return DataFrame with number of distinct observations per group for\n",
      " |      each column.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique: DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',\n",
      " |      ...                           'ham', 'ham'],\n",
      " |      ...                    'value1': [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'value2': list('abbaxy')})\n",
      " |      >>> df\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      1   egg       5      b\n",
      " |      2   egg       5      b\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |      \n",
      " |      >>> df.groupby('id').nunique()\n",
      " |          id  value1  value2\n",
      " |      id\n",
      " |      egg    1       1       1\n",
      " |      ham    1       1       2\n",
      " |      spam   1       2       1\n",
      " |      \n",
      " |      # check for rows with the same id but conflicting values\n",
      " |      >>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())\n",
      " |           id  value1 value2\n",
      " |      0  spam       1      a\n",
      " |      3  spam       2      a\n",
      " |      4   ham       5      x\n",
      " |      5   ham       5      y\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  corr\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float\n",
      " |              .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for pearson\n",
      " |          and spearman correlation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith\n",
      " |      Series.corr\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> histogram_intersection = lambda a, b: np.minimum(a, b\n",
      " |      ... ).sum().round(decimals=1)\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs cats\n",
      " |      dogs   1.0  0.3\n",
      " |      cats   0.3  1.0\n",
      " |  \n",
      " |  corrwith\n",
      " |      Compute pairwise correlation between rows or columns of DataFrame\n",
      " |      with rows or columns of Series or DataFrame.  DataFrames are first\n",
      " |      aligned along both axes before computing the correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n",
      " |      drop : boolean, default False\n",
      " |          Drop missing indices from result\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correls : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      -------\n",
      " |      DataFrame.corr\n",
      " |  \n",
      " |  cov\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.cov : Compute covariance with another Series.\n",
      " |      pandas.core.window.EWM.cov: Exponential weighted sample covariance.\n",
      " |      pandas.core.window.Expanding.cov : Expanding sample covariance.\n",
      " |      pandas.core.window.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-1.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <http://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  diff\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a DataFrame element compared with another\n",
      " |      element in the DataFrame (default is the element in the same column\n",
      " |      of the previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |          .. versionadded:: 0.16.1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff: First discrete difference for a Series.\n",
      " |      DataFrame.pct_change: Percent change over given number of periods.\n",
      " |      DataFrame.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a    b     c\n",
      " |      0 NaN  0.0   0.0\n",
      " |      1 NaN -1.0   3.0\n",
      " |      2 NaN -1.0   7.0\n",
      " |      3 NaN -1.0  13.0\n",
      " |      4 NaN  0.0  20.0\n",
      " |      5 NaN  2.0  28.0\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.ftypes : Dtype and sparsity information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  fillna\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                    columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  hist\n",
      " |      Make a histogram of the DataFrame's.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : string or sequence\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : boolean, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : boolean, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : integer or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      **kwds\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      axes : matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          This example draws a histogram based on the length and width of\n",
      " |          some animals, displayed in three bins\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index= ['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Series\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |  \n",
      " |  idxmin\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Series\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |  \n",
      " |  mad\n",
      " |      Return the mean absolute deviation of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  quantile\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default True\n",
      " |          If False, the quantile of datetime and timedelta data will be\n",
      " |          computed as well.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantiles : Series or DataFrame\n",
      " |      \n",
      " |          - If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          - If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |  \n",
      " |  skew\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  take\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      convert : bool, default True\n",
      " |          Whether to convert negative indices into positive ones.\n",
      " |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      " |          The conversions are similar to the behavior of indexing a\n",
      " |          regular Python list.\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |             In the future, negative indices will always be converted.\n",
      " |      \n",
      " |      is_copy : bool, default True\n",
      " |          Whether to return a copy of the original object or not.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                    columns=['name', 'class', 'max_speed'],\n",
      " |      ...                    index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  tshift\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from NDFrameGroupBy:\n",
      " |  \n",
      " |  filter(self, func, dropna=True, *args, **kwargs)\n",
      " |      Return a copy of a DataFrame excluding elements from groups that\n",
      " |      do not satisfy the boolean criterion specified by func.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each subframe. Should return True or False.\n",
      " |      dropna : Drop groups that do not pass the filter. True by default;\n",
      " |          if False, groups that evaluate False are filled with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filtered : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each subframe is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.filter(lambda x: x['B'].mean() > 3.)\n",
      " |           A  B    C\n",
      " |      1  bar  2  5.0\n",
      " |      3  bar  4  1.0\n",
      " |      5  bar  6  9.0\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed DataFrame on each group and\n",
      " |      return a DataFrame having the same indexes as the original object\n",
      " |      filled with the transformed values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each group\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      aggregate, transform\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each group is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      The current implementation imposes three requirements on f:\n",
      " |      \n",
      " |      * f must return a value that either has the same shape as the input\n",
      " |        subframe or can be broadcast to the shape of the input subframe.\n",
      " |        For example, f returns a scalar it will be broadcast to have the\n",
      " |        same shape as the input subframe.\n",
      " |      * if this is a DataFrame, f must support application column-by-column\n",
      " |        in the subframe. If f also supports application to the entire subframe,\n",
      " |        then a fast path is used starting from the second chunk.\n",
      " |      * f must not mutate groups. Mutation is not supported and may\n",
      " |        produce unexpected results.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      # Same shape\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      " |      ...                          'two', 'two'],\n",
      " |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                C         D\n",
      " |      0 -1.154701 -0.577350\n",
      " |      1  0.577350  0.000000\n",
      " |      2  0.577350  1.154701\n",
      " |      3 -1.154701 -1.000000\n",
      " |      4  0.577350 -0.577350\n",
      " |      5  0.577350  1.000000\n",
      " |      \n",
      " |      # Broadcastable\n",
      " |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      " |         C    D\n",
      " |      0  4  6.0\n",
      " |      1  3  8.0\n",
      " |      2  4  6.0\n",
      " |      3  3  8.0\n",
      " |      4  4  6.0\n",
      " |      5  3  8.0\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby.GroupBy:\n",
      " |  \n",
      " |  all(self, skipna=True)\n",
      " |      Returns True if all values in the group are truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  any(self, skipna=True)\n",
      " |      Returns True if any value in the group is truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  backfill(self, limit=None)\n",
      " |      Backward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.backfill\n",
      " |      DataFrame.backfill\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  bfill = backfill(self, limit=None)\n",
      " |  \n",
      " |  cumcount(self, ascending=True)\n",
      " |      Number each item in each group from 0 to the length of that group - 1.\n",
      " |      \n",
      " |      Essentially this is equivalent to\n",
      " |      \n",
      " |      >>> self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from length of group - 1 to 0.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .ngroup : Number the groups themselves.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').cumcount()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    0\n",
      " |      4    1\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').cumcount(ascending=False)\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    1\n",
      " |      4    0\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cummax(self, axis=0, **kwargs)\n",
      " |      Cumulative max for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cummin(self, axis=0, **kwargs)\n",
      " |      Cumulative min for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumprod(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative product for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumsum(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative sum for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  describe(self, **kwargs)\n",
      " |      Generate descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the obersvations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  expanding(self, *args, **kwargs)\n",
      " |      Return an expanding grouper, providing expanding\n",
      " |      functionality per group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ffill = pad(self, limit=None)\n",
      " |  \n",
      " |  first(self, **kwargs)\n",
      " |      Compute first of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows of each group.\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.head(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      " |                            columns=['A', 'B'])\n",
      " |      >>> df.groupby('A', as_index=False).head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |  \n",
      " |  last(self, **kwargs)\n",
      " |      Compute last of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  max(self, **kwargs)\n",
      " |      Compute max of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  mean(self, *args, **kwargs)\n",
      " |      Compute mean of groups, excluding missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series or pandas.DataFrame\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5],\n",
      " |      ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Groupby one column and return the mean of the remaining columns in\n",
      " |      each group.\n",
      " |      \n",
      " |      >>> df.groupby('A').mean()\n",
      " |      >>>\n",
      " |           B         C\n",
      " |      A\n",
      " |      1  3.0  1.333333\n",
      " |      2  4.0  1.500000\n",
      " |      \n",
      " |      Groupby two columns and return the mean of the remaining column.\n",
      " |      \n",
      " |      >>> df.groupby(['A', 'B']).mean()\n",
      " |      >>>\n",
      " |             C\n",
      " |      A B\n",
      " |      1 2.0  2\n",
      " |        4.0  1\n",
      " |      2 3.0  1\n",
      " |        5.0  2\n",
      " |      \n",
      " |      Groupby one column and return the mean of only particular column in\n",
      " |      the group.\n",
      " |      \n",
      " |      >>> df.groupby('A')['B'].mean()\n",
      " |      >>>\n",
      " |      A\n",
      " |      1    3.0\n",
      " |      2    4.0\n",
      " |      Name: B, dtype: float64\n",
      " |  \n",
      " |  median(self, **kwargs)\n",
      " |      Compute median of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  min(self, **kwargs)\n",
      " |      Compute min of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ngroup(self, ascending=True)\n",
      " |      Number each group from 0 to the number of groups - 1.\n",
      " |      \n",
      " |      This is the enumerative complement of cumcount.  Note that the\n",
      " |      numbers given to the groups match the order in which the groups\n",
      " |      would be seen when iterating over the groupby object, not the\n",
      " |      order they are first observed.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.2\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from number of group - 1 to 0.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .cumcount : Number the rows in each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    1\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').ngroup(ascending=False)\n",
      " |      0    1\n",
      " |      1    1\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      4    0\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    3\n",
      " |      4    2\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  nth(self, n, dropna=None)\n",
      " |      Take the nth row from each group if n is an int, or a subset of rows\n",
      " |      if n is a list of ints.\n",
      " |      \n",
      " |      If dropna, will take the nth non-null row, dropna is either\n",
      " |      Truthy (if a Series) or 'all', 'any' (if a DataFrame);\n",
      " |      this is equivalent to calling dropna(how=dropna) before the\n",
      " |      groupby.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int or list of ints\n",
      " |          a single nth value for the row or a list of nth values\n",
      " |      dropna : None or str, optional\n",
      " |          apply the specified dropna operation before counting which row is\n",
      " |          the nth row. Needs to be None, 'any' or 'all'\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      " |      >>> g = df.groupby('A')\n",
      " |      >>> g.nth(0)\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      >>> g.nth(1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth(-1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  4.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth([0, 1])\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      2  5.0\n",
      " |      \n",
      " |      Specifying `dropna` allows count ignoring ``NaN``\n",
      " |      \n",
      " |      >>> g.nth(0, dropna='any')\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      \n",
      " |      NaNs denote group exhausted when using dropna\n",
      " |      \n",
      " |      >>> g.nth(3, dropna='any')\n",
      " |          B\n",
      " |      A\n",
      " |      1 NaN\n",
      " |      2 NaN\n",
      " |      \n",
      " |      Specifying `as_index=False` in `groupby` keeps the original index.\n",
      " |      \n",
      " |      >>> df.groupby('A', as_index=False).nth(1)\n",
      " |         A    B\n",
      " |      1  1  2.0\n",
      " |      4  2  5.0\n",
      " |  \n",
      " |  ohlc(self)\n",
      " |      Compute sum of values, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  pad(self, limit=None)\n",
      " |      Forward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pad\n",
      " |      DataFrame.pad\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, axis=0)\n",
      " |      Calculate pct_change of each value to previous entry in group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  prod(self, **kwargs)\n",
      " |      Compute prod of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  rank(self, method='average', ascending=True, na_option='keep', pct=False, axis=0)\n",
      " |      Provides the rank of values within each group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      na_option :  {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      pct : boolean, default False\n",
      " |          Compute percentage rank of data within each group\n",
      " |      axis : int, default 0\n",
      " |          The axis of the object over which to compute the rank.\n",
      " |      \n",
      " |      Returns\n",
      " |      -----\n",
      " |      DataFrame with ranking of values within each group\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  resample(self, rule, *args, **kwargs)\n",
      " |      Provide resampling when using a TimeGrouper.\n",
      " |      \n",
      " |      Given a grouper, the function resamples it according to a string\n",
      " |      \"string\" -> \"frequency\".\n",
      " |      \n",
      " |      See the :ref:`frequency aliases <timeseries.offset_aliases>`\n",
      " |      documentation for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : str or DateOffset\n",
      " |          The offset string or object representing target grouper conversion.\n",
      " |      *args, **kwargs\n",
      " |          Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n",
      " |          `on`, and other arguments of `TimeGrouper`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Grouper\n",
      " |          Return a new grouper with our resampler appended.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Grouper : Specify a frequency to resample with when\n",
      " |          grouping by a key.\n",
      " |      DatetimeIndex.resample : Frequency conversion and resampling of\n",
      " |          time series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> df = pd.DataFrame(data=4 * [range(2)],\n",
      " |      ...                   index=idx,\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.iloc[2, 0] = 5\n",
      " |      >>> df\n",
      " |                          a  b\n",
      " |      2000-01-01 00:00:00  0  1\n",
      " |      2000-01-01 00:01:00  0  1\n",
      " |      2000-01-01 00:02:00  5  1\n",
      " |      2000-01-01 00:03:00  0  1\n",
      " |      \n",
      " |      Downsample the DataFrame into 3 minute bins and sum the values of\n",
      " |      the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  2\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('30S').sum()\n",
      " |                          a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:00:30  0  0\n",
      " |          2000-01-01 00:01:00  0  1\n",
      " |          2000-01-01 00:01:30  0  0\n",
      " |          2000-01-01 00:02:00  0  0\n",
      " |          2000-01-01 00:02:30  0  0\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:02:00  5  1\n",
      " |      \n",
      " |      Resample by month. Values are assigned to the month of the period.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('M').sum()\n",
      " |                  a  b\n",
      " |      a\n",
      " |      0   2000-01-31  0  3\n",
      " |      5   2000-01-31  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   1999-12-31 23:57:00  0  1\n",
      " |          2000-01-01 00:00:00  0  2\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and close the right side of\n",
      " |      the bin interval, but label each bin using the right edge instead of\n",
      " |      the left.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:03:00  0  2\n",
      " |      5   2000-01-01 00:03:00  5  1\n",
      " |      \n",
      " |      Add an offset of twenty seconds.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', loffset='20s').sum()\n",
      " |                             a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:20  0  2\n",
      " |          2000-01-01 00:03:20  0  1\n",
      " |      5   2000-01-01 00:00:20  5  1\n",
      " |  \n",
      " |  rolling(self, *args, **kwargs)\n",
      " |      Return a rolling grouper, providing rolling functionality per group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sem(self, ddof=1)\n",
      " |      Compute standard error of the mean of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0, fill_value=None)\n",
      " |      Shift each group by periods observations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : integer, default 1\n",
      " |          number of periods to shift\n",
      " |      freq : frequency string\n",
      " |      axis : axis to shift, default 0\n",
      " |      fill_value : optional\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  size(self)\n",
      " |      Compute group sizes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  std(self, ddof=1, *args, **kwargs)\n",
      " |      Compute standard deviation of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sum(self, **kwargs)\n",
      " |      Compute sum of group values\n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows of each group.\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.tail(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.%(name)s\n",
      " |      pandas.DataFrame.%(name)s\n",
      " |      pandas.Panel.%(name)s\n",
      " |      \n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      " |                            columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').tail(1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      2  b  1\n",
      " |  \n",
      " |  var(self, ddof=1, *args, **kwargs)\n",
      " |      Compute variance of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby._GroupBy:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __init__(self, obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Groupby iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Generator yielding sequence of (name, subsetted object)\n",
      " |      for each group\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by unicode(obj) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  apply(self, func, *args, **kwargs)\n",
      " |      Apply function `func`  group-wise and combine the results together.\n",
      " |      \n",
      " |      The function passed to `apply` must take a dataframe as its first\n",
      " |      argument and return a DataFrame, Series or scalar. `apply` will\n",
      " |      then take care of combining the results back together into a single\n",
      " |      dataframe or series. `apply` is therefore a highly flexible\n",
      " |      grouping method.\n",
      " |      \n",
      " |      While `apply` is a very flexible method, its downside is that\n",
      " |      using it can be quite a bit slower than using more specific methods\n",
      " |      like `agg` or `transform`. Pandas offers a wide range of method that will\n",
      " |      be much faster than using `apply` for their specific purposes, so try to\n",
      " |      use them before reaching for `apply`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          A callable that takes a dataframe as its first argument, and\n",
      " |          returns a dataframe, a series or a scalar. In addition the\n",
      " |          callable may take positional and keyword arguments.\n",
      " |      args, kwargs : tuple and dict\n",
      " |          Optional positional and keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pipe : Apply function to the full GroupBy object instead of to each\n",
      " |          group.\n",
      " |      aggregate : Apply aggregate function to the GroupBy object.\n",
      " |      transform : Apply function column-by-column to the GroupBy object.\n",
      " |      Series.apply : Apply a function to a Series.\n",
      " |      DataFrame.apply : Apply a function to each row or column of a DataFrame.\n",
      " |  \n",
      " |  get_group(self, name, obj=None)\n",
      " |      Constructs NDFrame from group with provided name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object\n",
      " |          the name of the group to get as a DataFrame\n",
      " |      obj : NDFrame, default None\n",
      " |          the NDFrame to take the DataFrame out of.  If\n",
      " |          it is None, the object groupby was called on will\n",
      " |          be used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      group : same type as obj\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply a function `func` with arguments to this GroupBy object and return\n",
      " |      the function's result.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Use `.pipe` when you want to improve readability by chaining together\n",
      " |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      " |      Instead of writing\n",
      " |      \n",
      " |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.groupby('group')\n",
      " |      ...    .pipe(f)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(h, arg2=b, arg3=c))\n",
      " |      \n",
      " |      which is much more readable.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable or tuple of (callable, string)\n",
      " |          Function to apply to this GroupBy object or, alternatively,\n",
      " |          a `(callable, data_keyword)` tuple where `data_keyword` is a\n",
      " |          string indicating the keyword of `callable` that expects the\n",
      " |          GroupBy object.\n",
      " |      args : iterable, optional\n",
      " |             positional arguments passed into `func`.\n",
      " |      kwargs : dict, optional\n",
      " |               a dictionary of keyword arguments passed into `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of `func`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.pipe : Apply a function with arguments to a series.\n",
      " |      pandas.DataFrame.pipe: Apply a function with arguments to a dataframe.\n",
      " |      apply : Apply function to each group instead of to the\n",
      " |          full GroupBy object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See more `here\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html#piping-function-calls>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      1  b  2\n",
      " |      2  a  3\n",
      " |      3  b  4\n",
      " |      \n",
      " |      To get the difference between each groups maximum and minimum value in one\n",
      " |      pass, you can do\n",
      " |      \n",
      " |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      " |         B\n",
      " |      A\n",
      " |      a  2\n",
      " |      b  2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.groupby.groupby._GroupBy:\n",
      " |  \n",
      " |  groups\n",
      " |      Dict {group name -> group labels}.\n",
      " |  \n",
      " |  indices\n",
      " |      Dict {group name -> group indices}.\n",
      " |  \n",
      " |  ngroups\n",
      " |  \n",
      " |  plot\n",
      " |      Class implementing the .plot attribute for groupby objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  ndim\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bike_sharing.groupby(\"season\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>11.821534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>21.528425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>29.232093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>18.625167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             temp\n",
       "season           \n",
       "1.0     11.821534\n",
       "2.0     21.528425\n",
       "3.0     29.232093\n",
       "4.0     18.625167"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i want season-wise mean temperature - assignment\n",
    "bike_sharing.groupby(\"season\").agg({\"temp\":\"mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#To change data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6493 entries, 0 to 6492\n",
      "Data columns (total 9 columns):\n",
      "datetime      6492 non-null object\n",
      "season        6489 non-null float64\n",
      "holiday       6491 non-null float64\n",
      "workingday    6490 non-null float64\n",
      "weather       6490 non-null float64\n",
      "temp          6490 non-null float64\n",
      "atemp         6490 non-null float64\n",
      "humidity      6491 non-null float64\n",
      "windspeed     6491 non-null float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 456.6+ KB\n"
     ]
    }
   ],
   "source": [
    "bike_sharing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To convert season into a string. but remember to overwrite the same column otherwise the change will not be permanent\n",
    "bike_sharing[\"season\"] = bike_sharing[\"season\"].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6493 entries, 0 to 6492\n",
      "Data columns (total 9 columns):\n",
      "datetime      6492 non-null object\n",
      "season        6489 non-null object\n",
      "holiday       6491 non-null float64\n",
      "workingday    6490 non-null float64\n",
      "weather       6490 non-null float64\n",
      "temp          6490 non-null float64\n",
      "atemp         6490 non-null float64\n",
      "humidity      6491 non-null float64\n",
      "windspeed     6491 non-null float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 456.6+ KB\n"
     ]
    }
   ],
   "source": [
    "bike_sharing.info()\n",
    "# the season was converted into an object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    1763\n",
       "2.0    1676\n",
       "1.0    1552\n",
       "4.0    1498\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to identify if a category or an object has space. For example, how many unique seasons and their frequency but this\n",
    "#does not show the null values\n",
    "bike_sharing[\"season\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, nan, 2.0, 3.0, 4.0], dtype=object)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To find unique values\n",
    "bike_sharing[\"season\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(bike_sharing[\"season\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1/20/2011 22:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>10.605</td>\n",
       "      <td>65.0</td>\n",
       "      <td>19.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1/21/2011 18:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6.060</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1/21/2011 23:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>22.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1/23/2011 10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>5.305</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1/25/2011 23:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.365</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1/27/2011 23:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.850</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1/29/2011 7:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            datetime season  holiday  workingday  weather  temp   atemp  \\\n",
       "22   1/20/2011 22:00    NaN      0.0         1.0      2.0  9.84  10.605   \n",
       "42   1/21/2011 18:00      1      0.0         1.0      NaN  4.92   6.060   \n",
       "47   1/21/2011 23:00      1      0.0         1.0      1.0  2.46     NaN   \n",
       "64               NaN    NaN      NaN         NaN      NaN   NaN     NaN   \n",
       "80   1/23/2011 10:00    NaN      0.0         0.0      1.0  5.74   5.305   \n",
       "139  1/25/2011 23:00      1      0.0         1.0      2.0   NaN  11.365   \n",
       "163  1/27/2011 23:00      1      0.0         NaN      1.0  7.38   9.850   \n",
       "193   1/29/2011 7:00    NaN      NaN         NaN      NaN   NaN     NaN   \n",
       "\n",
       "     humidity  windspeed  \n",
       "22       65.0    19.0012  \n",
       "42       30.0    16.9979  \n",
       "47       38.0    22.0028  \n",
       "64        NaN        NaN  \n",
       "80       46.0    26.0027  \n",
       "139      64.0    11.0014  \n",
       "163      80.0    11.0014  \n",
       "193       NaN        NaN  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing[bike_sharing.isnull().any(axis=1)]\n",
    "#here it will not take axis =0, it will take by column - if any of the column is null is the only one taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we can do value_counts once we have found the null values (usually in the beginning of analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#in bike sharing, instead of numeric temp , i want to convert it into a range or a category. We want to temp column like this. \n",
    "# this is called binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_bin=[0,10,20,30,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = [\"0-10\",\"10-20\",\"20-30\",\"30-40\"]\n",
    "#This is a string. we can give anything we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10-20\n",
       "1       10-20\n",
       "2       10-20\n",
       "3       10-20\n",
       "4       10-20\n",
       "5        0-10\n",
       "6        0-10\n",
       "7        0-10\n",
       "8        0-10\n",
       "9        0-10\n",
       "10      10-20\n",
       "11      10-20\n",
       "12      10-20\n",
       "13      10-20\n",
       "14      10-20\n",
       "15      10-20\n",
       "16      10-20\n",
       "17      10-20\n",
       "18      10-20\n",
       "19      10-20\n",
       "20      10-20\n",
       "21       0-10\n",
       "22       0-10\n",
       "23       0-10\n",
       "24       0-10\n",
       "25       0-10\n",
       "26       0-10\n",
       "27       0-10\n",
       "28       0-10\n",
       "29       0-10\n",
       "        ...  \n",
       "6463     0-10\n",
       "6464    10-20\n",
       "6465     0-10\n",
       "6466     0-10\n",
       "6467     0-10\n",
       "6468     0-10\n",
       "6469     0-10\n",
       "6470     0-10\n",
       "6471     0-10\n",
       "6472     0-10\n",
       "6473     0-10\n",
       "6474     0-10\n",
       "6475     0-10\n",
       "6476     0-10\n",
       "6477     0-10\n",
       "6478     0-10\n",
       "6479     0-10\n",
       "6480     0-10\n",
       "6481     0-10\n",
       "6482    10-20\n",
       "6483    10-20\n",
       "6484    10-20\n",
       "6485    10-20\n",
       "6486    10-20\n",
       "6487    10-20\n",
       "6488    10-20\n",
       "6489    10-20\n",
       "6490    10-20\n",
       "6491    10-20\n",
       "6492    10-20\n",
       "Name: temp, Length: 6493, dtype: category\n",
       "Categories (4, object): [0-10 < 10-20 < 20-30 < 30-40]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(bike_sharing[\"temp\"],bins=temp_bin,labels=bin_labels)\n",
    "#pd.cut, pass the column you want to bin. in bins pass how many bins we want to create and what is your labels.pd.cut will form \n",
    "# a bin between \"0-10\" and \"0\", \"10-20\" and \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column called temp_range\n",
    "bike_sharing[\"temp_range\"] = pd.cut(bike_sharing[\"temp\"],bins=temp_bin,labels=bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>temp_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/20/2011 0:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0027</td>\n",
       "      <td>10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/20/2011 1:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/20/2011 2:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/20/2011 3:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/20/2011 4:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         datetime season  holiday  workingday  weather   temp   atemp  \\\n",
       "0  1/20/2011 0:00      1      0.0         1.0      1.0  10.66  11.365   \n",
       "1  1/20/2011 1:00      1      0.0         1.0      1.0  10.66  13.635   \n",
       "2  1/20/2011 2:00      1      0.0         1.0      1.0  10.66  13.635   \n",
       "3  1/20/2011 3:00      1      0.0         1.0      1.0  10.66  12.880   \n",
       "4  1/20/2011 4:00      1      0.0         1.0      1.0  10.66  12.880   \n",
       "\n",
       "   humidity  windspeed temp_range  \n",
       "0      56.0    26.0027      10-20  \n",
       "1      56.0     0.0000      10-20  \n",
       "2      56.0     0.0000      10-20  \n",
       "3      56.0    11.0014      10-20  \n",
       "4      56.0    11.0014      10-20  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#THIS IS HOW WE CONVERT A NUMERIC COLUMN TO A RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the windspeed column to a range 0,20,40,60\n",
    "wind_bin = [0,20,40,60]\n",
    "bin_labels = [\"0-20\",\"20-40\",\"40-60\"]\n",
    "bike_sharing[\"windspeed_range\"]=pd.cut(bike_sharing[\"windspeed\"],bins=wind_bin,labels=bin_labels)\n",
    "#Created a new column called 'windspeed_range'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>temp_range</th>\n",
       "      <th>windspeed_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/20/2011 0:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0027</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/20/2011 1:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/20/2011 2:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/20/2011 3:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/20/2011 4:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/20/2011 5:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/20/2011 6:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/20/2011 7:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/20/2011 8:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/20/2011 9:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/20/2011 10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.9995</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1/20/2011 11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>13.635</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/20/2011 12:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>16.665</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1/20/2011 13:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>14.395</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1/20/2011 14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1/20/2011 15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>15.910</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1/20/2011 16:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1/20/2011 17:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.910</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1/20/2011 18:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1/20/2011 19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22.0028</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime season  holiday  workingday  weather   temp   atemp  \\\n",
       "0    1/20/2011 0:00      1      0.0         1.0      1.0  10.66  11.365   \n",
       "1    1/20/2011 1:00      1      0.0         1.0      1.0  10.66  13.635   \n",
       "2    1/20/2011 2:00      1      0.0         1.0      1.0  10.66  13.635   \n",
       "3    1/20/2011 3:00      1      0.0         1.0      1.0  10.66  12.880   \n",
       "4    1/20/2011 4:00      1      0.0         1.0      1.0  10.66  12.880   \n",
       "5    1/20/2011 5:00      1      0.0         1.0      1.0   9.84  11.365   \n",
       "6    1/20/2011 6:00      1      0.0         1.0      1.0   9.02  10.605   \n",
       "7    1/20/2011 7:00      1      0.0         1.0      1.0   9.02  10.605   \n",
       "8    1/20/2011 8:00      1      0.0         1.0      1.0   9.02  10.605   \n",
       "9    1/20/2011 9:00      1      0.0         1.0      2.0   9.84  11.365   \n",
       "10  1/20/2011 10:00      1      0.0         1.0      1.0  10.66  11.365   \n",
       "11  1/20/2011 11:00      1      0.0         1.0      2.0  11.48  13.635   \n",
       "12  1/20/2011 12:00      1      0.0         1.0      2.0  12.30  16.665   \n",
       "13  1/20/2011 13:00      1      0.0         1.0      2.0  11.48  14.395   \n",
       "14  1/20/2011 14:00      1      0.0         1.0      2.0  12.30  15.150   \n",
       "15  1/20/2011 15:00      1      0.0         1.0      2.0  13.12  15.910   \n",
       "16  1/20/2011 16:00      1      0.0         1.0      2.0  12.30  15.150   \n",
       "17  1/20/2011 17:00      1      0.0         1.0      2.0  12.30  15.910   \n",
       "18  1/20/2011 18:00      1      0.0         1.0      2.0  10.66  12.880   \n",
       "19  1/20/2011 19:00      1      0.0         1.0      1.0  10.66  11.365   \n",
       "\n",
       "    humidity  windspeed temp_range windspeed_range  \n",
       "0       56.0    26.0027      10-20           20-40  \n",
       "1       56.0     0.0000      10-20             NaN  \n",
       "2       56.0     0.0000      10-20             NaN  \n",
       "3       56.0    11.0014      10-20            0-20  \n",
       "4       56.0    11.0014      10-20            0-20  \n",
       "5       60.0    15.0013       0-10            0-20  \n",
       "6       60.0    15.0013       0-10            0-20  \n",
       "7       55.0    15.0013       0-10            0-20  \n",
       "8       55.0    19.0012       0-10            0-20  \n",
       "9       52.0    15.0013       0-10            0-20  \n",
       "10      48.0    19.9995      10-20            0-20  \n",
       "11      45.0    11.0014      10-20            0-20  \n",
       "12      42.0     0.0000      10-20             NaN  \n",
       "13      45.0     7.0015      10-20            0-20  \n",
       "14      45.0     8.9981      10-20            0-20  \n",
       "15      45.0    12.9980      10-20            0-20  \n",
       "16      49.0     8.9981      10-20            0-20  \n",
       "17      49.0     7.0015      10-20            0-20  \n",
       "18      56.0    12.9980      10-20            0-20  \n",
       "19      56.0    22.0028      10-20           20-40  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is another kind of binning to do on existing code\n",
    "bike_sharing.loc[(bike_sharing[\"temp\"]>0) & (bike_sharing[\"temp\"]<10),\"New_temp\"] = \"0-10\"\n",
    "#Usually this is not preferred but same thing can be done easier using pd.cut\n",
    "#bike_sharing.loc[(bike_sharing[\"temp\"]>10) & (bike_sharing[\"temp\"]<20),\"New_temp\"] = \"10-20\"\n",
    "#If you use the second line, then it will update for all the columns of 10-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>temp_range</th>\n",
       "      <th>windspeed_range</th>\n",
       "      <th>New_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/20/2011 0:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0027</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/20/2011 1:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/20/2011 2:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/20/2011 3:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/20/2011 4:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/20/2011 5:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "      <td>0-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/20/2011 6:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "      <td>0-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/20/2011 7:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "      <td>0-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/20/2011 8:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.605</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "      <td>0-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/20/2011 9:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.365</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>0-10</td>\n",
       "      <td>0-20</td>\n",
       "      <td>0-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/20/2011 10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.9995</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1/20/2011 11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>13.635</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/20/2011 12:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>16.665</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1/20/2011 13:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.48</td>\n",
       "      <td>14.395</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1/20/2011 14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1/20/2011 15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>15.910</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1/20/2011 16:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1/20/2011 17:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.910</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1/20/2011 18:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.9980</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1/20/2011 19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22.0028</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime season  holiday  workingday  weather   temp   atemp  \\\n",
       "0    1/20/2011 0:00      1      0.0         1.0      1.0  10.66  11.365   \n",
       "1    1/20/2011 1:00      1      0.0         1.0      1.0  10.66  13.635   \n",
       "2    1/20/2011 2:00      1      0.0         1.0      1.0  10.66  13.635   \n",
       "3    1/20/2011 3:00      1      0.0         1.0      1.0  10.66  12.880   \n",
       "4    1/20/2011 4:00      1      0.0         1.0      1.0  10.66  12.880   \n",
       "5    1/20/2011 5:00      1      0.0         1.0      1.0   9.84  11.365   \n",
       "6    1/20/2011 6:00      1      0.0         1.0      1.0   9.02  10.605   \n",
       "7    1/20/2011 7:00      1      0.0         1.0      1.0   9.02  10.605   \n",
       "8    1/20/2011 8:00      1      0.0         1.0      1.0   9.02  10.605   \n",
       "9    1/20/2011 9:00      1      0.0         1.0      2.0   9.84  11.365   \n",
       "10  1/20/2011 10:00      1      0.0         1.0      1.0  10.66  11.365   \n",
       "11  1/20/2011 11:00      1      0.0         1.0      2.0  11.48  13.635   \n",
       "12  1/20/2011 12:00      1      0.0         1.0      2.0  12.30  16.665   \n",
       "13  1/20/2011 13:00      1      0.0         1.0      2.0  11.48  14.395   \n",
       "14  1/20/2011 14:00      1      0.0         1.0      2.0  12.30  15.150   \n",
       "15  1/20/2011 15:00      1      0.0         1.0      2.0  13.12  15.910   \n",
       "16  1/20/2011 16:00      1      0.0         1.0      2.0  12.30  15.150   \n",
       "17  1/20/2011 17:00      1      0.0         1.0      2.0  12.30  15.910   \n",
       "18  1/20/2011 18:00      1      0.0         1.0      2.0  10.66  12.880   \n",
       "19  1/20/2011 19:00      1      0.0         1.0      1.0  10.66  11.365   \n",
       "\n",
       "    humidity  windspeed temp_range windspeed_range New_temp  \n",
       "0       56.0    26.0027      10-20           20-40      NaN  \n",
       "1       56.0     0.0000      10-20             NaN      NaN  \n",
       "2       56.0     0.0000      10-20             NaN      NaN  \n",
       "3       56.0    11.0014      10-20            0-20      NaN  \n",
       "4       56.0    11.0014      10-20            0-20      NaN  \n",
       "5       60.0    15.0013       0-10            0-20     0-10  \n",
       "6       60.0    15.0013       0-10            0-20     0-10  \n",
       "7       55.0    15.0013       0-10            0-20     0-10  \n",
       "8       55.0    19.0012       0-10            0-20     0-10  \n",
       "9       52.0    15.0013       0-10            0-20     0-10  \n",
       "10      48.0    19.9995      10-20            0-20      NaN  \n",
       "11      45.0    11.0014      10-20            0-20      NaN  \n",
       "12      42.0     0.0000      10-20             NaN      NaN  \n",
       "13      45.0     7.0015      10-20            0-20      NaN  \n",
       "14      45.0     8.9981      10-20            0-20      NaN  \n",
       "15      45.0    12.9980      10-20            0-20      NaN  \n",
       "16      49.0     8.9981      10-20            0-20      NaN  \n",
       "17      49.0     7.0015      10-20            0-20      NaN  \n",
       "18      56.0    12.9980      10-20            0-20      NaN  \n",
       "19      56.0    22.0028      10-20           20-40      NaN  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is map\n",
    "### map(function,iterable in list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Athlete</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Event</th>\n",
       "      <th>Event_gender</th>\n",
       "      <th>Medal</th>\n",
       "      <th>Country</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>HAJOS, Alfred</td>\n",
       "      <td>HUN</td>\n",
       "      <td>Men</td>\n",
       "      <td>100m freestyle</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "      <td>Greek</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>HERSCHMANN, Otto</td>\n",
       "      <td>AUT</td>\n",
       "      <td>Men</td>\n",
       "      <td>100m freestyle</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Greek</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AUT</td>\n",
       "      <td>Men</td>\n",
       "      <td>100m freestyle</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Greek</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>MALOKINIS, Ioannis</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Men</td>\n",
       "      <td>100m freestyle for sailors</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "      <td>Greek</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     City  Edition     Sport Discipline             Athlete  NOC Gender  \\\n",
       "0  Athens   1896.0  Aquatics   Swimming       HAJOS, Alfred  HUN    Men   \n",
       "1  Athens   1896.0  Aquatics   Swimming    HERSCHMANN, Otto  AUT    Men   \n",
       "2  Athens   1896.0  Aquatics   Swimming                 NaN  AUT    Men   \n",
       "3     NaN      NaN       NaN        NaN                 NaN  NaN    NaN   \n",
       "4  Athens   1896.0  Aquatics   Swimming  MALOKINIS, Ioannis  GRE    Men   \n",
       "\n",
       "                        Event Event_gender   Medal Country country  \n",
       "0              100m freestyle            M    Gold   Greek   Greek  \n",
       "1              100m freestyle            M  Silver   Greek   Greek  \n",
       "2              100m freestyle            M  Silver   Greek   Greek  \n",
       "3                         NaN          NaN     NaN     NaN     NaN  \n",
       "4  100m freestyle for sailors            M    Gold   Greek   Greek  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#help(pd.read_csv)\n",
    "#olympic_data = pd.read_csv(\"C:/Users/tin2419/Desktop/DSFiles/olympics.csv\",skiprows=4)\n",
    "#olympic_data.head() \n",
    "#To create a column where we can map some countries to some of the cities. The functionality is actually map\n",
    "\n",
    "country_map={\"Athens\":\"Greek\",\"Berlin\":\"Russia\"}\n",
    "#olympic_data[\"city\"].map(country_map)- for the key value - city, it will return me Athens\n",
    "olympic_data[\"country\"] = olympic_data[\"City\"].map(country_map) \n",
    "#will create a new column called 'country' and match the values\n",
    "olympic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map(square,[1,2,3,4]) \n",
    "#this will square the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Water Sports\n",
       "1        Water Sports\n",
       "2        Water Sports\n",
       "3                 NaN\n",
       "4        Water Sports\n",
       "5        Water Sports\n",
       "6        Water Sports\n",
       "7        Water Sports\n",
       "8        Water Sports\n",
       "9        Water Sports\n",
       "10       Water Sports\n",
       "11       Water Sports\n",
       "12            Running\n",
       "13            Running\n",
       "14            Running\n",
       "15            Running\n",
       "16            Running\n",
       "17            Running\n",
       "18            Running\n",
       "19            Running\n",
       "20            Running\n",
       "21            Running\n",
       "22            Running\n",
       "23            Running\n",
       "24            Running\n",
       "25            Running\n",
       "26            Running\n",
       "27            Running\n",
       "28            Running\n",
       "29            Running\n",
       "             ...     \n",
       "29187       Wrestling\n",
       "29188       Wrestling\n",
       "29189       Wrestling\n",
       "29190       Wrestling\n",
       "29191       Wrestling\n",
       "29192       Wrestling\n",
       "29193       Wrestling\n",
       "29194       Wrestling\n",
       "29195       Wrestling\n",
       "29196       Wrestling\n",
       "29197       Wrestling\n",
       "29198       Wrestling\n",
       "29199       Wrestling\n",
       "29200       Wrestling\n",
       "29201       Wrestling\n",
       "29202       Wrestling\n",
       "29203       Wrestling\n",
       "29204       Wrestling\n",
       "29205       Wrestling\n",
       "29206       Wrestling\n",
       "29207       Wrestling\n",
       "29208       Wrestling\n",
       "29209       Wrestling\n",
       "29210       Wrestling\n",
       "29211       Wrestling\n",
       "29212       Wrestling\n",
       "29213       Wrestling\n",
       "29214       Wrestling\n",
       "29215       Wrestling\n",
       "29216       Wrestling\n",
       "Name: Sport, Length: 29217, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in few cases, we will need to replace some values. WE have a method called replace\n",
    "#olympic_data[\"Sport\"].replace(\"Aquatics\",\"Water Sports\")\n",
    "olympic_data[\"Sport\"].replace({\"Aquatics\":\"Water Sports\",\"Athletics\":\"Running\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount=pd.Series([\"$20000\",\"$30000\"])\n",
    "#Instead of DataFrame, we could use Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    $20000\n",
       "1    $30000\n",
       "dtype: object"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    $20000\n",
       "1    $30000\n",
       "dtype: object"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount.replace(\"$\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20000\n",
       "1    30000\n",
       "dtype: object"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this will not work as replace is a string function. \n",
    "amount.str.replace(\"$\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Earlier we replacing Athens we are not replacing part of the value. When we need to replace part of \n",
    "# the value, then we will have to convert it into a string. Like if we replace 20000 with 25000 then \n",
    "#we don't need a string.str. But to convert a part,we need to convert it into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6493 entries, 0 to 6492\n",
      "Data columns (total 12 columns):\n",
      "datetime           6492 non-null object\n",
      "season             6489 non-null object\n",
      "holiday            6491 non-null float64\n",
      "workingday         6490 non-null float64\n",
      "weather            6490 non-null float64\n",
      "temp               6490 non-null float64\n",
      "atemp              6490 non-null float64\n",
      "humidity           6491 non-null float64\n",
      "windspeed          6491 non-null float64\n",
      "temp_range         6489 non-null category\n",
      "windspeed_range    5625 non-null category\n",
      "New_temp           751 non-null object\n",
      "dtypes: category(2), float64(7), object(3)\n",
      "memory usage: 520.3+ KB\n"
     ]
    }
   ],
   "source": [
    "bike_sharing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>temp_range</th>\n",
       "      <th>windspeed_range</th>\n",
       "      <th>New_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/20/2011 0:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0027</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/20/2011 1:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/20/2011 2:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/20/2011 3:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/20/2011 4:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         datetime season  holiday  workingday  weather   temp   atemp  \\\n",
       "0  1/20/2011 0:00      1      0.0         1.0      1.0  10.66  11.365   \n",
       "1  1/20/2011 1:00      1      0.0         1.0      1.0  10.66  13.635   \n",
       "2  1/20/2011 2:00      1      0.0         1.0      1.0  10.66  13.635   \n",
       "3  1/20/2011 3:00      1      0.0         1.0      1.0  10.66  12.880   \n",
       "4  1/20/2011 4:00      1      0.0         1.0      1.0  10.66  12.880   \n",
       "\n",
       "   humidity  windspeed temp_range windspeed_range New_temp  \n",
       "0      56.0    26.0027      10-20           20-40      NaN  \n",
       "1      56.0     0.0000      10-20             NaN      NaN  \n",
       "2      56.0     0.0000      10-20             NaN      NaN  \n",
       "3      56.0    11.0014      10-20            0-20      NaN  \n",
       "4      56.0    11.0014      10-20            0-20      NaN  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here to convert the datetime to a datetime object we use pd.to_datetime\n",
    "bike_sharing.head()\n",
    "# here datetime is a sring type, if i want the hour,date etc, then i will have to do string slicing \n",
    "#which will make the coding complex. Converting into pandas datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_sharing[\"datetime\"]=pd.to_datetime(bike_sharing[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6493 entries, 0 to 6492\n",
      "Data columns (total 9 columns):\n",
      "datetime      6492 non-null object\n",
      "season        6489 non-null float64\n",
      "holiday       6491 non-null float64\n",
      "workingday    6490 non-null float64\n",
      "weather       6490 non-null float64\n",
      "temp          6490 non-null float64\n",
      "atemp         6490 non-null float64\n",
      "humidity      6491 non-null float64\n",
      "windspeed     6491 non-null float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 456.6+ KB\n"
     ]
    }
   ],
   "source": [
    "bike_sharing.info()\n",
    "#Now it has become a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    3.0\n",
       "4    4.0\n",
       "Name: datetime, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing[\"datetime\"].dt.hour.head()\n",
    "#type(bike_sharing[\"datetime\"].dt.hour)# it is a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2011-01-20\n",
       "1    2011-01-20\n",
       "2    2011-01-20\n",
       "3    2011-01-20\n",
       "4    2011-01-20\n",
       "Name: datetime, dtype: object"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing[\"datetime\"].dt.date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20.0\n",
       "1    20.0\n",
       "2    20.0\n",
       "3    20.0\n",
       "4    20.0\n",
       "Name: datetime, dtype: float64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing[\"datetime\"].dt.day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "Name: datetime, dtype: float64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing[\"datetime\"].dt.month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2011.0\n",
       "1    2011.0\n",
       "2    2011.0\n",
       "3    2011.0\n",
       "4    2011.0\n",
       "Name: datetime, dtype: float64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_sharing[\"datetime\"].dt.year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Thursday\n",
       "1    Thursday\n",
       "2    Thursday\n",
       "3    Thursday\n",
       "4    Thursday\n",
       "Name: datetime, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get day of the week\n",
    "bike_sharing[\"datetime\"].dt.weekday_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-05-10 00:00:00')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to name the day of the week - check help\n",
    "pd.to_datetime(\"05/10/2010\")\n",
    "#weekday_name is there to get the name of the week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-10-05 00:00:00')"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WE can give the format \n",
    "pd.to_datetime(\"05/10/2019\",format=\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-06-06 00:00:00')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert into pandas date format and get me the date, year and month\n",
    "date_str1='Wednesday,June 6,2018'\n",
    "date_str2='6/6/18'\n",
    "date_str3='06-06-2018'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-06-01 00:00:00')"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the above into pandas datetime\n",
    "pd.to_datetime(date_str1,format ='%A,%B %m,%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-06-06 00:00:00')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(date_str2,format ='%m/%d/%y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-06-06 00:00:00')"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(date_str3,format='%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2011-01-20 00:00:00\n",
       "1   2011-01-20 01:00:00\n",
       "2   2011-01-20 02:00:00\n",
       "3   2011-01-20 03:00:00\n",
       "4   2011-01-20 04:00:00\n",
       "Name: datetime, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(bike_sharing[\"datetime\"]).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6492, 9)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Give me all the rows where datetime > '2010-01-01' \n",
    "bike_sharing[pd.to_datetime(bike_sharing[\"datetime\"])>'2010-01-01'].shape\n",
    "#bike_sharing[bike_sharing[\"datetime\"]>\"2010-01-01\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function to_datetime in module pandas.core.tools.datetimes:\n",
      "\n",
      "to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False, utc=None, box=True, format=None, exact=True, unit=None, infer_datetime_format=False, origin='unix', cache=False)\n",
      "    Convert argument to datetime.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    arg : integer, float, string, datetime, list, tuple, 1-d array, Series\n",
      "    \n",
      "        .. versionadded:: 0.18.1\n",
      "    \n",
      "           or DataFrame/dict-like\n",
      "    \n",
      "    errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
      "    \n",
      "        - If 'raise', then invalid parsing will raise an exception\n",
      "        - If 'coerce', then invalid parsing will be set as NaT\n",
      "        - If 'ignore', then invalid parsing will return the input\n",
      "    dayfirst : boolean, default False\n",
      "        Specify a date parse order if `arg` is str or its list-likes.\n",
      "        If True, parses dates with the day first, eg 10/11/12 is parsed as\n",
      "        2012-11-10.\n",
      "        Warning: dayfirst=True is not strict, but will prefer to parse\n",
      "        with day first (this is a known bug, based on dateutil behavior).\n",
      "    yearfirst : boolean, default False\n",
      "        Specify a date parse order if `arg` is str or its list-likes.\n",
      "    \n",
      "        - If True parses dates with the year first, eg 10/11/12 is parsed as\n",
      "          2010-11-12.\n",
      "        - If both dayfirst and yearfirst are True, yearfirst is preceded (same\n",
      "          as dateutil).\n",
      "    \n",
      "        Warning: yearfirst=True is not strict, but will prefer to parse\n",
      "        with year first (this is a known bug, based on dateutil behavior).\n",
      "    \n",
      "        .. versionadded:: 0.16.1\n",
      "    \n",
      "    utc : boolean, default None\n",
      "        Return UTC DatetimeIndex if True (converting any tz-aware\n",
      "        datetime.datetime objects as well).\n",
      "    box : boolean, default True\n",
      "    \n",
      "        - If True returns a DatetimeIndex or Index-like object\n",
      "        - If False returns ndarray of values.\n",
      "    format : string, default None\n",
      "        strftime to parse time, eg \"%d/%m/%Y\", note that \"%f\" will parse\n",
      "        all the way up to nanoseconds.\n",
      "    exact : boolean, True by default\n",
      "    \n",
      "        - If True, require an exact format match.\n",
      "        - If False, allow the format to match anywhere in the target string.\n",
      "    \n",
      "    unit : string, default 'ns'\n",
      "        unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
      "        integer or float number. This will be based off the origin.\n",
      "        Example, with unit='ms' and origin='unix' (the default), this\n",
      "        would calculate the number of milliseconds to the unix epoch start.\n",
      "    infer_datetime_format : boolean, default False\n",
      "        If True and no `format` is given, attempt to infer the format of the\n",
      "        datetime strings, and if it can be inferred, switch to a faster\n",
      "        method of parsing them. In some cases this can increase the parsing\n",
      "        speed by ~5-10x.\n",
      "    origin : scalar, default is 'unix'\n",
      "        Define the reference date. The numeric values would be parsed as number\n",
      "        of units (defined by `unit`) since this reference date.\n",
      "    \n",
      "        - If 'unix' (or POSIX) time; origin is set to 1970-01-01.\n",
      "        - If 'julian', unit must be 'D', and origin is set to beginning of\n",
      "          Julian Calendar. Julian day number 0 is assigned to the day starting\n",
      "          at noon on January 1, 4713 BC.\n",
      "        - If Timestamp convertible, origin is set to Timestamp identified by\n",
      "          origin.\n",
      "    \n",
      "        .. versionadded:: 0.20.0\n",
      "    cache : boolean, default False\n",
      "        If True, use a cache of unique, converted dates to apply the datetime\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "        .. versionadded:: 0.23.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ret : datetime if parsing succeeded.\n",
      "        Return type depends on input:\n",
      "    \n",
      "        - list-like: DatetimeIndex\n",
      "        - Series: Series of datetime64 dtype\n",
      "        - scalar: Timestamp\n",
      "    \n",
      "        In case when it is not possible to return designated types (e.g. when\n",
      "        any element of input is before Timestamp.min or after Timestamp.max)\n",
      "        return will have datetime.datetime type (or corresponding\n",
      "        array/Series).\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    pandas.DataFrame.astype : Cast argument to a specified dtype.\n",
      "    pandas.to_timedelta : Convert argument to timedelta.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Assembling a datetime from multiple columns of a DataFrame. The keys can be\n",
      "    common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
      "    'ms', 'us', 'ns']) or plurals of the same\n",
      "    \n",
      "    >>> df = pd.DataFrame({'year': [2015, 2016],\n",
      "                           'month': [2, 3],\n",
      "                           'day': [4, 5]})\n",
      "    >>> pd.to_datetime(df)\n",
      "    0   2015-02-04\n",
      "    1   2016-03-05\n",
      "    dtype: datetime64[ns]\n",
      "    \n",
      "    If a date does not meet the `timestamp limitations\n",
      "    <http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
      "    #timeseries-timestamp-limits>`_, passing errors='ignore'\n",
      "    will return the original input instead of raising any exception.\n",
      "    \n",
      "    Passing errors='coerce' will force an out-of-bounds date to NaT,\n",
      "    in addition to forcing non-dates (or non-parseable dates) to NaT.\n",
      "    \n",
      "    >>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
      "    datetime.datetime(1300, 1, 1, 0, 0)\n",
      "    >>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
      "    NaT\n",
      "    \n",
      "    Passing infer_datetime_format=True can often-times speedup a parsing\n",
      "    if its not an ISO8601 format exactly, but in a regular format.\n",
      "    \n",
      "    >>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000']*1000)\n",
      "    \n",
      "    >>> s.head()\n",
      "    0    3/11/2000\n",
      "    1    3/12/2000\n",
      "    2    3/13/2000\n",
      "    3    3/11/2000\n",
      "    4    3/12/2000\n",
      "    dtype: object\n",
      "    \n",
      "    >>> %timeit pd.to_datetime(s,infer_datetime_format=True)\n",
      "    100 loops, best of 3: 10.4 ms per loop\n",
      "    \n",
      "    >>> %timeit pd.to_datetime(s,infer_datetime_format=False)\n",
      "    1 loop, best of 3: 471 ms per loop\n",
      "    \n",
      "    Using a unix epoch time\n",
      "    \n",
      "    >>> pd.to_datetime(1490195805, unit='s')\n",
      "    Timestamp('2017-03-22 15:16:45')\n",
      "    >>> pd.to_datetime(1490195805433502912, unit='ns')\n",
      "    Timestamp('2017-03-22 15:16:45.433502912')\n",
      "    \n",
      "    .. warning:: For float arg, precision rounding might happen. To prevent\n",
      "        unexpected behavior use a fixed-width exact type.\n",
      "    \n",
      "    Using a non-unix epoch origin\n",
      "    \n",
      "    >>> pd.to_datetime([1, 2, 3], unit='D',\n",
      "                       origin=pd.Timestamp('1960-01-01'))\n",
      "    0    1960-01-02\n",
      "    1    1960-01-03\n",
      "    2    1960-01-04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#convert it into '01/01/2010' and then compare\n",
    "#bike_sharing[pd.to_datetime(bike_sharing[\"datetime\"],format='%d/%m/%Y') > '01/01/2010']\n",
    "#This is how you can play around with the date\n",
    "\n",
    "#ASSIGNMENT - PRACTICE EVERYTHING WITH BITE SHARING DATA\n",
    "help(pd.to_datetime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(bike_sharing_date,format='%m-%d-%Y')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
